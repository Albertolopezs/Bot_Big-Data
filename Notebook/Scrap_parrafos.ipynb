{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parrafos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "\n",
    "driver = None\n",
    "\n",
    "def load_driver(url):\n",
    "    \"\"\" Logging into our own profile \"\"\"\n",
    "\n",
    "    try:\n",
    "        global driver\n",
    "\n",
    "        options = Options()\n",
    "\n",
    "        #  Code to disable notifications pop up of Chrome Browser\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--disable-infobars\")\n",
    "        options.add_argument(\"--mute-audio\")\n",
    "        # options.add_argument(\"headless\")\n",
    "\n",
    "        try:\n",
    "            platform_ = platform.system().lower()\n",
    "            print(platform_)\n",
    "            if platform_ in ['linux', 'darwin']:\n",
    "                print(webdriver.Chrome(executable_path=\"./chromedriver\", options=options))\n",
    "                driver = webdriver.Chrome(executable_path=\"./chromedriver\", options=options)\n",
    "            else:\n",
    "                driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\", options=options)\n",
    "        except:\n",
    "            print(\"Kindly replace the Chrome Web Driver with the latest one from\"\n",
    "                  \"http://chromedriver.chromium.org/downloads\"\n",
    "                  \"\\nYour OS: {}\".format(platform_)\n",
    "                 )\n",
    "            exit()\n",
    "\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"There's some error in log in.\")\n",
    "        print(sys.exc_info()[0])\n",
    "        print(e)\n",
    "        exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# //section[@id='main']//*[preceding::h3[\"+str(i+1)+\"] and following::h3[\"+str(14-i)+\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sk_learn():\n",
    "    global title,descriptions,codeBlock,url_word,url_attachment\n",
    "    url = \"https://scikit-learn.org/stable/user_guide.html\"\n",
    "    load_driver(url)\n",
    "    for i in range(1,8):\n",
    "        _block = driver.find_elements_by_xpath(\"//li[@class='toctree-l1'][\"+str(i)+\"]\")\n",
    "        _mainSection = driver.find_elements_by_xpath(\"//li[@class='toctree-l1'][\"+str(i)+\"]/ul/li/a\")                                       \n",
    "        for k in range(len(_mainSection)):\n",
    "            _mainSection = driver.find_elements_by_xpath(\"//li[@class='toctree-l1'][\"+str(i)+\"]/ul/li/a\")    \n",
    "            sect = _mainSection[k]\n",
    "            driver.get(sect.get_attribute(\"href\"))\n",
    "            _titles = driver.find_elements_by_xpath(\"//h2\")\n",
    "            for j in range(1,len(_titles)+1):\n",
    "                _textP = driver.find_elements_by_xpath(\"//div[@class='section']/div[@class='section'][\"+str(j)+\"]/p\")\n",
    "                _title = _titles[j-1].text\n",
    "                _code = driver.find_elements_by_xpath(\"//div[@class='section']/div[@class='section'][\"+str(j)+\"]//pre\")\n",
    "                _img = driver.find_elements_by_xpath(\"//div[@class='section']/div[@class='section'][\"+str(j)+\"]//img\")\n",
    "                _text = \"\"\n",
    "                _codeText = []\n",
    "                _imgSrc = []\n",
    "                for p in _textP:\n",
    "                    _text += p.text + \"\\n\"\n",
    "                for code in _code:\n",
    "                    _codeText.append(code.text)\n",
    "                for img in _img:\n",
    "                    _imgSrc.append(img.get_attribute(\"src\"))\n",
    "                title.append(_title)\n",
    "                descriptions.append(_text)\n",
    "                codeBlock.append(_codeText)\n",
    "                url_word.append(driver.current_url)\n",
    "                url_attachment.append(_imgSrc)\n",
    "                print(_title)\n",
    "                print(_text)\n",
    "                print(_codeText)\n",
    "            driver.back()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_learn():\n",
    "    global title,descriptions,codeBlock,url_word,url_attachment\n",
    "    url = \"https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\"\n",
    "    load_driver(url)\n",
    "    _titles = driver.find_elements_by_xpath(\"//h2\")\n",
    "    for i in range(1,len(_titles)):\n",
    "        print(i,len(_titles))\n",
    "        _path = \"//div[@class='section']/div[@class='section'][\"+str(i)+\"]\"\n",
    "        _codeBlocks = driver.find_elements_by_xpath(\"//pre[preceding::h2[\"+str(i)+\"] and following::h2[\"+str(len(_titles)-i)+\"]]\")\n",
    "\n",
    "        _pre = driver.find_elements_by_xpath(\"//pre\")\n",
    "        #Get the index of the first pre element\n",
    "        _preIndex = 0\n",
    "        for _pre_ind in range(1,len(_pre)):\n",
    "            \n",
    "            if(_pre[_pre_ind] == _codeBlocks[0]):\n",
    "                _preIndex = _pre_ind\n",
    "                break\n",
    "\n",
    "        for j in range(len(_codeBlocks)):\n",
    "            print(len(_codeBlocks),j, _preIndex+j,len(_pre)-(_preIndex+j))\n",
    "            _textP = driver.find_elements_by_xpath(_path+\"//p[preceding::pre[\"+str(_preIndex+j)+\"] and following::pre[\"+str(len(_pre)-(_preIndex+j))+\"]]\")\n",
    "            _img = driver.find_elements_by_xpath(_path+\"//img[preceding::pre[\"+str(_preIndex+j)+\"] and following::pre[\"+str(len(_pre)-(_preIndex+j))+\"]]\")\n",
    "            _title = driver.find_element_by_xpath(_path+\"/h2\").text\n",
    "            _imgSrc = []\n",
    "            _text = \"\"\n",
    "            for _i in _img:\n",
    "                _imgSrc.append(_i.get_attribute(\"src\"))\n",
    "            for _textPj in _textP:\n",
    "                _text += _textPj.text\n",
    "            _codeText = _codeBlocks[j].text\n",
    "            print(_title)\n",
    "            print(_text)\n",
    "            print(_codeText)\n",
    "            title.append(_title)\n",
    "            descriptions.append(_text)\n",
    "            codeBlock.append(_codeText)\n",
    "            url_word.append(driver.current_url)\n",
    "            url_attachment.append(_imgSrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darwin\n",
      "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"35a52a9af683346fa35445d58b7089b3\")>\n",
      "1 13\n",
      "5 0 1 79\n",
      "Object Creation\n",
      "See the Data Structure Intro section.Creating a Series by passing a list of values, letting pandas create a default integer index:\n",
      "In [3]: s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
      "\n",
      "In [4]: s\n",
      "Out[4]: \n",
      "0    1.0\n",
      "1    3.0\n",
      "2    5.0\n",
      "3    NaN\n",
      "4    6.0\n",
      "5    8.0\n",
      "dtype: float64\n",
      "5 1 2 78\n",
      "Object Creation\n",
      "Creating a DataFrame by passing a NumPy array, with a datetime index and labeled columns:\n",
      "In [5]: dates = pd.date_range('20130101', periods=6)\n",
      "\n",
      "In [6]: dates\n",
      "Out[6]: \n",
      "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
      "               '2013-01-05', '2013-01-06'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "\n",
      "In [7]: df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
      "\n",
      "In [8]: df\n",
      "Out[8]: \n",
      "                   A         B         C         D\n",
      "2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
      "2013-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
      "2013-01-06 -0.673690  0.113648 -1.478427  0.524988\n",
      "5 2 3 77\n",
      "Object Creation\n",
      "Creating a DataFrame by passing a dict of objects that can be converted to series-like.\n",
      "In [9]: df2 = pd.DataFrame({'A': 1.,\n",
      "   ...:                     'B': pd.Timestamp('20130102'),\n",
      "   ...:                     'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
      "   ...:                     'D': np.array([3] * 4, dtype='int32'),\n",
      "   ...:                     'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
      "   ...:                     'F': 'foo'})\n",
      "   ...: \n",
      "\n",
      "In [10]: df2\n",
      "Out[10]: \n",
      "     A          B    C  D      E    F\n",
      "0  1.0 2013-01-02  1.0  3   test  foo\n",
      "1  1.0 2013-01-02  1.0  3  train  foo\n",
      "2  1.0 2013-01-02  1.0  3   test  foo\n",
      "3  1.0 2013-01-02  1.0  3  train  foo\n",
      "5 3 4 76\n",
      "Object Creation\n",
      "The columns of the resulting DataFrame have different dtypes.\n",
      "In [11]: df2.dtypes\n",
      "Out[11]: \n",
      "A           float64\n",
      "B    datetime64[ns]\n",
      "C           float32\n",
      "D             int32\n",
      "E          category\n",
      "F            object\n",
      "dtype: object\n",
      "5 4 5 75\n",
      "Object Creation\n",
      "If you’re using IPython, tab completion for column names (as well as public attributes) is automatically enabled. Here’s a subset of the attributes that will be completed:\n",
      "In [12]: df2.<TAB>  # noqa: E225, E999\n",
      "df2.A                  df2.bool\n",
      "df2.abs                df2.boxplot\n",
      "df2.add                df2.C\n",
      "df2.add_prefix         df2.clip\n",
      "df2.add_suffix         df2.clip_lower\n",
      "df2.align              df2.clip_upper\n",
      "df2.all                df2.columns\n",
      "df2.any                df2.combine\n",
      "df2.append             df2.combine_first\n",
      "df2.apply              df2.compound\n",
      "df2.applymap           df2.consolidate\n",
      "df2.D\n",
      "2 13\n",
      "8 0 6 74\n",
      "Viewing Data\n",
      "See the Basics section.Here is how to view the top and bottom rows of the frame:\n",
      "In [13]: df.head()\n",
      "Out[13]: \n",
      "                   A         B         C         D\n",
      "2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
      "2013-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
      "\n",
      "In [14]: df.tail(3)\n",
      "Out[14]: \n",
      "                   A         B         C         D\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
      "2013-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
      "2013-01-06 -0.673690  0.113648 -1.478427  0.524988\n",
      "8 1 7 73\n",
      "Viewing Data\n",
      "Display the index, columns:\n",
      "In [15]: df.index\n",
      "Out[15]: \n",
      "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
      "               '2013-01-05', '2013-01-06'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "\n",
      "In [16]: df.columns\n",
      "Out[16]: Index(['A', 'B', 'C', 'D'], dtype='object')\n",
      "8 2 8 72\n",
      "Viewing Data\n",
      "DataFrame.to_numpy() gives a NumPy representation of the underlying data. Note that his can be an expensive operation when your DataFrame has columns with different data types, which comes down to a fundamental difference between pandas and NumPy: NumPy arrays have one dtype for the entire array, while pandas DataFrames have one dtype per column. When you call DataFrame.to_numpy(), pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. This may end up being object, which requires casting every value to a Python object.For df, our DataFrame of all floating-point values, DataFrame.to_numpy() is fast and doesn’t require copying data.\n",
      "In [17]: df.to_numpy()\n",
      "Out[17]: \n",
      "array([[ 0.4691, -0.2829, -1.5091, -1.1356],\n",
      "       [ 1.2121, -0.1732,  0.1192, -1.0442],\n",
      "       [-0.8618, -2.1046, -0.4949,  1.0718],\n",
      "       [ 0.7216, -0.7068, -1.0396,  0.2719],\n",
      "       [-0.425 ,  0.567 ,  0.2762, -1.0874],\n",
      "       [-0.6737,  0.1136, -1.4784,  0.525 ]])\n",
      "8 3 9 71\n",
      "Viewing Data\n",
      "For df2, the DataFrame with multiple dtypes, DataFrame.to_numpy() is relatively expensive.\n",
      "In [18]: df2.to_numpy()\n",
      "Out[18]: \n",
      "array([[1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],\n",
      "       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo'],\n",
      "       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],\n",
      "       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo']], dtype=object)\n",
      "8 4 10 70\n",
      "Viewing Data\n",
      "NoteDataFrame.to_numpy() does not include the index or column labels in the output.describe() shows a quick statistic summary of your data:\n",
      "In [19]: df.describe()\n",
      "Out[19]: \n",
      "              A         B         C         D\n",
      "count  6.000000  6.000000  6.000000  6.000000\n",
      "mean   0.073711 -0.431125 -0.687758 -0.233103\n",
      "std    0.843157  0.922818  0.779887  0.973118\n",
      "min   -0.861849 -2.104569 -1.509059 -1.135632\n",
      "25%   -0.611510 -0.600794 -1.368714 -1.076610\n",
      "50%    0.022070 -0.228039 -0.767252 -0.386188\n",
      "75%    0.658444  0.041933 -0.034326  0.461706\n",
      "max    1.212112  0.567020  0.276232  1.071804\n",
      "8 5 11 69\n",
      "Viewing Data\n",
      "Transposing your data:\n",
      "In [20]: df.T\n",
      "Out[20]: \n",
      "   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06\n",
      "A    0.469112    1.212112   -0.861849    0.721555   -0.424972   -0.673690\n",
      "B   -0.282863   -0.173215   -2.104569   -0.706771    0.567020    0.113648\n",
      "C   -1.509059    0.119209   -0.494929   -1.039575    0.276232   -1.478427\n",
      "D   -1.135632   -1.044236    1.071804    0.271860   -1.087401    0.524988\n",
      "8 6 12 68\n",
      "Viewing Data\n",
      "Sorting by an axis:\n",
      "In [21]: df.sort_index(axis=1, ascending=False)\n",
      "Out[21]: \n",
      "                   D         C         B         A\n",
      "2013-01-01 -1.135632 -1.509059 -0.282863  0.469112\n",
      "2013-01-02 -1.044236  0.119209 -0.173215  1.212112\n",
      "2013-01-03  1.071804 -0.494929 -2.104569 -0.861849\n",
      "2013-01-04  0.271860 -1.039575 -0.706771  0.721555\n",
      "2013-01-05 -1.087401  0.276232  0.567020 -0.424972\n",
      "2013-01-06  0.524988 -1.478427  0.113648 -0.673690\n",
      "8 7 13 67\n",
      "Viewing Data\n",
      "Sorting by values:\n",
      "In [22]: df.sort_values(by='B')\n",
      "Out[22]: \n",
      "                   A         B         C         D\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
      "2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
      "2013-01-06 -0.673690  0.113648 -1.478427  0.524988\n",
      "2013-01-05 -0.424972  0.567020  0.276232 -1.087401\n",
      "3 13\n",
      "24 0 14 66\n",
      "Selection\n",
      "NoteWhile standard Python / Numpy expressions for selecting and setting are intuitive and come in handy for interactive work, for production code, we recommend the optimized pandas data access methods, .at, .iat, .loc and .iloc.See the indexing documentation Indexing and Selecting Data and MultiIndex / Advanced Indexing.Selecting a single column, which yields a Series, equivalent to df.A:\n",
      "In [23]: df['A']\n",
      "Out[23]: \n",
      "2013-01-01    0.469112\n",
      "2013-01-02    1.212112\n",
      "2013-01-03   -0.861849\n",
      "2013-01-04    0.721555\n",
      "2013-01-05   -0.424972\n",
      "2013-01-06   -0.673690\n",
      "Freq: D, Name: A, dtype: float64\n",
      "24 1 15 65\n",
      "Selection\n",
      "Selecting via [], which slices the rows.\n",
      "In [24]: df[0:3]\n",
      "Out[24]: \n",
      "                   A         B         C         D\n",
      "2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
      "\n",
      "In [25]: df['20130102':'20130104']\n",
      "Out[25]: \n",
      "                   A         B         C         D\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
      "24 2 16 64\n",
      "Selection\n",
      "See more in Selection by Label.For getting a cross section using a label:\n",
      "In [26]: df.loc[dates[0]]\n",
      "Out[26]: \n",
      "A    0.469112\n",
      "B   -0.282863\n",
      "C   -1.509059\n",
      "D   -1.135632\n",
      "Name: 2013-01-01 00:00:00, dtype: float64\n",
      "24 3 17 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection\n",
      "Selecting on a multi-axis by label:\n",
      "In [27]: df.loc[:, ['A', 'B']]\n",
      "Out[27]: \n",
      "                   A         B\n",
      "2013-01-01  0.469112 -0.282863\n",
      "2013-01-02  1.212112 -0.173215\n",
      "2013-01-03 -0.861849 -2.104569\n",
      "2013-01-04  0.721555 -0.706771\n",
      "2013-01-05 -0.424972  0.567020\n",
      "2013-01-06 -0.673690  0.113648\n",
      "24 4 18 62\n",
      "Selection\n",
      "Showing label slicing, both endpoints are included:\n",
      "In [28]: df.loc['20130102':'20130104', ['A', 'B']]\n",
      "Out[28]: \n",
      "                   A         B\n",
      "2013-01-02  1.212112 -0.173215\n",
      "2013-01-03 -0.861849 -2.104569\n",
      "2013-01-04  0.721555 -0.706771\n",
      "24 5 19 61\n",
      "Selection\n",
      "Reduction in the dimensions of the returned object:\n",
      "In [29]: df.loc['20130102', ['A', 'B']]\n",
      "Out[29]: \n",
      "A    1.212112\n",
      "B   -0.173215\n",
      "Name: 2013-01-02 00:00:00, dtype: float64\n",
      "24 6 20 60\n",
      "Selection\n",
      "For getting a scalar value:\n",
      "In [30]: df.loc[dates[0], 'A']\n",
      "Out[30]: 0.46911229990718628\n",
      "24 7 21 59\n",
      "Selection\n",
      "For getting fast access to a scalar (equivalent to the prior method):\n",
      "In [31]: df.at[dates[0], 'A']\n",
      "Out[31]: 0.46911229990718628\n",
      "24 8 22 58\n",
      "Selection\n",
      "See more in Selection by Position.Select via the position of the passed integers:\n",
      "In [32]: df.iloc[3]\n",
      "Out[32]: \n",
      "A    0.721555\n",
      "B   -0.706771\n",
      "C   -1.039575\n",
      "D    0.271860\n",
      "Name: 2013-01-04 00:00:00, dtype: float64\n",
      "24 9 23 57\n",
      "Selection\n",
      "By integer slices, acting similar to numpy/python:\n",
      "In [33]: df.iloc[3:5, 0:2]\n",
      "Out[33]: \n",
      "                   A         B\n",
      "2013-01-04  0.721555 -0.706771\n",
      "2013-01-05 -0.424972  0.567020\n",
      "24 10 24 56\n",
      "Selection\n",
      "By lists of integer position locations, similar to the numpy/python style:\n",
      "In [34]: df.iloc[[1, 2, 4], [0, 2]]\n",
      "Out[34]: \n",
      "                   A         C\n",
      "2013-01-02  1.212112  0.119209\n",
      "2013-01-03 -0.861849 -0.494929\n",
      "2013-01-05 -0.424972  0.276232\n",
      "24 11 25 55\n",
      "Selection\n",
      "For slicing rows explicitly:\n",
      "In [35]: df.iloc[1:3, :]\n",
      "Out[35]: \n",
      "                   A         B         C         D\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\n",
      "24 12 26 54\n",
      "Selection\n",
      "For slicing columns explicitly:\n",
      "In [36]: df.iloc[:, 1:3]\n",
      "Out[36]: \n",
      "                   B         C\n",
      "2013-01-01 -0.282863 -1.509059\n",
      "2013-01-02 -0.173215  0.119209\n",
      "2013-01-03 -2.104569 -0.494929\n",
      "2013-01-04 -0.706771 -1.039575\n",
      "2013-01-05  0.567020  0.276232\n",
      "2013-01-06  0.113648 -1.478427\n",
      "24 13 27 53\n",
      "Selection\n",
      "For getting a value explicitly:\n",
      "In [37]: df.iloc[1, 1]\n",
      "Out[37]: -0.17321464905330858\n",
      "24 14 28 52\n",
      "Selection\n",
      "For getting fast access to a scalar (equivalent to the prior method):\n",
      "In [38]: df.iat[1, 1]\n",
      "Out[38]: -0.17321464905330858\n",
      "24 15 29 51\n",
      "Selection\n",
      "Using a single column’s values to select data.\n",
      "In [39]: df[df.A > 0]\n",
      "Out[39]: \n",
      "                   A         B         C         D\n",
      "2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n",
      "24 16 30 50\n",
      "Selection\n",
      "Selecting values from a DataFrame where a boolean condition is met.\n",
      "In [40]: df[df > 0]\n",
      "Out[40]: \n",
      "                   A         B         C         D\n",
      "2013-01-01  0.469112       NaN       NaN       NaN\n",
      "2013-01-02  1.212112       NaN  0.119209       NaN\n",
      "2013-01-03       NaN       NaN       NaN  1.071804\n",
      "2013-01-04  0.721555       NaN       NaN  0.271860\n",
      "2013-01-05       NaN  0.567020  0.276232       NaN\n",
      "2013-01-06       NaN  0.113648       NaN  0.524988\n",
      "24 17 31 49\n",
      "Selection\n",
      "Using the isin() method for filtering:\n",
      "In [41]: df2 = df.copy()\n",
      "\n",
      "In [42]: df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\n",
      "\n",
      "In [43]: df2\n",
      "Out[43]: \n",
      "                   A         B         C         D      E\n",
      "2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one\n",
      "2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three\n",
      "2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four\n",
      "2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three\n",
      "\n",
      "In [44]: df2[df2['E'].isin(['two', 'four'])]\n",
      "Out[44]: \n",
      "                   A         B         C         D     E\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two\n",
      "2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four\n",
      "24 18 32 48\n",
      "Selection\n",
      "Setting a new column automatically aligns the data by the indexes.\n",
      "In [45]: s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range('20130102', periods=6))\n",
      "\n",
      "In [46]: s1\n",
      "Out[46]: \n",
      "2013-01-02    1\n",
      "2013-01-03    2\n",
      "2013-01-04    3\n",
      "2013-01-05    4\n",
      "2013-01-06    5\n",
      "2013-01-07    6\n",
      "Freq: D, dtype: int64\n",
      "\n",
      "In [47]: df['F'] = s1\n",
      "24 19 33 47\n",
      "Selection\n",
      "Setting values by label:\n",
      "In [48]: df.at[dates[0], 'A'] = 0\n",
      "24 20 34 46\n",
      "Selection\n",
      "Setting values by position:\n",
      "In [49]: df.iat[0, 1] = 0\n",
      "24 21 35 45\n",
      "Selection\n",
      "Setting by assigning with a NumPy array:\n",
      "In [50]: df.loc[:, 'D'] = np.array([5] * len(df))\n",
      "24 22 36 44\n",
      "Selection\n",
      "The result of the prior setting operations.\n",
      "In [51]: df\n",
      "Out[51]: \n",
      "                   A         B         C  D    F\n",
      "2013-01-01  0.000000  0.000000 -1.509059  5  NaN\n",
      "2013-01-02  1.212112 -0.173215  0.119209  5  1.0\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  5  3.0\n",
      "2013-01-05 -0.424972  0.567020  0.276232  5  4.0\n",
      "2013-01-06 -0.673690  0.113648 -1.478427  5  5.0\n",
      "24 23 37 43\n",
      "Selection\n",
      "A where operation with setting.\n",
      "In [52]: df2 = df.copy()\n",
      "\n",
      "In [53]: df2[df2 > 0] = -df2\n",
      "\n",
      "In [54]: df2\n",
      "Out[54]: \n",
      "                   A         B         C  D    F\n",
      "2013-01-01  0.000000  0.000000 -1.509059 -5  NaN\n",
      "2013-01-02 -1.212112 -0.173215 -0.119209 -5 -1.0\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929 -5 -2.0\n",
      "2013-01-04 -0.721555 -0.706771 -1.039575 -5 -3.0\n",
      "2013-01-05 -0.424972 -0.567020 -0.276232 -5 -4.0\n",
      "2013-01-06 -0.673690 -0.113648 -1.478427 -5 -5.0\n",
      "4 13\n",
      "4 0 38 42\n",
      "Missing Data\n",
      "pandas primarily uses the value np.nan to represent missing data. It is by default not included in computations. See the Missing Data section.Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data.\n",
      "In [55]: df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
      "\n",
      "In [56]: df1.loc[dates[0]:dates[1], 'E'] = 1\n",
      "\n",
      "In [57]: df1\n",
      "Out[57]: \n",
      "                   A         B         C  D    F    E\n",
      "2013-01-01  0.000000  0.000000 -1.509059  5  NaN  1.0\n",
      "2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0  NaN\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  5  3.0  NaN\n",
      "4 1 39 41\n",
      "Missing Data\n",
      "To drop any rows that have missing data.\n",
      "In [58]: df1.dropna(how='any')\n",
      "Out[58]: \n",
      "                   A         B         C  D    F    E\n",
      "2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0\n",
      "4 2 40 40\n",
      "Missing Data\n",
      "Filling missing data.\n",
      "In [59]: df1.fillna(value=5)\n",
      "Out[59]: \n",
      "                   A         B         C  D    F    E\n",
      "2013-01-01  0.000000  0.000000 -1.509059  5  5.0  1.0\n",
      "2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0\n",
      "2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0  5.0\n",
      "2013-01-04  0.721555 -0.706771 -1.039575  5  3.0  5.0\n",
      "4 3 41 39\n",
      "Missing Data\n",
      "To get the boolean mask where values are nan.\n",
      "In [60]: pd.isna(df1)\n",
      "Out[60]: \n",
      "                A      B      C      D      F      E\n",
      "2013-01-01  False  False  False  False   True  False\n",
      "2013-01-02  False  False  False  False  False  False\n",
      "2013-01-03  False  False  False  False  False   True\n",
      "2013-01-04  False  False  False  False  False   True\n",
      "5 13\n",
      "6 0 42 38\n",
      "Operations\n",
      "See the Basic section on Binary Ops.Operations in general exclude missing data.Performing a descriptive statistic:\n",
      "In [61]: df.mean()\n",
      "Out[61]: \n",
      "A   -0.004474\n",
      "B   -0.383981\n",
      "C   -0.687758\n",
      "D    5.000000\n",
      "F    3.000000\n",
      "dtype: float64\n",
      "6 1 43 37\n",
      "Operations\n",
      "Same operation on the other axis:\n",
      "In [62]: df.mean(1)\n",
      "Out[62]: \n",
      "2013-01-01    0.872735\n",
      "2013-01-02    1.431621\n",
      "2013-01-03    0.707731\n",
      "2013-01-04    1.395042\n",
      "2013-01-05    1.883656\n",
      "2013-01-06    1.592306\n",
      "Freq: D, dtype: float64\n",
      "6 2 44 36\n",
      "Operations\n",
      "Operating with objects that have different dimensionality and need alignment. In addition, pandas automatically broadcasts along the specified dimension.\n",
      "In [63]: s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)\n",
      "\n",
      "In [64]: s\n",
      "Out[64]: \n",
      "2013-01-01    NaN\n",
      "2013-01-02    NaN\n",
      "2013-01-03    1.0\n",
      "2013-01-04    3.0\n",
      "2013-01-05    5.0\n",
      "2013-01-06    NaN\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "In [65]: df.sub(s, axis='index')\n",
      "Out[65]: \n",
      "                   A         B         C    D    F\n",
      "2013-01-01       NaN       NaN       NaN  NaN  NaN\n",
      "2013-01-02       NaN       NaN       NaN  NaN  NaN\n",
      "2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0\n",
      "2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0\n",
      "2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0\n",
      "2013-01-06       NaN       NaN       NaN  NaN  NaN\n",
      "6 3 45 35\n",
      "Operations\n",
      "Applying functions to the data:\n",
      "In [66]: df.apply(np.cumsum)\n",
      "Out[66]: \n",
      "                   A         B         C   D     F\n",
      "2013-01-01  0.000000  0.000000 -1.509059   5   NaN\n",
      "2013-01-02  1.212112 -0.173215 -1.389850  10   1.0\n",
      "2013-01-03  0.350263 -2.277784 -1.884779  15   3.0\n",
      "2013-01-04  1.071818 -2.984555 -2.924354  20   6.0\n",
      "2013-01-05  0.646846 -2.417535 -2.648122  25  10.0\n",
      "2013-01-06 -0.026844 -2.303886 -4.126549  30  15.0\n",
      "\n",
      "In [67]: df.apply(lambda x: x.max() - x.min())\n",
      "Out[67]: \n",
      "A    2.073961\n",
      "B    2.671590\n",
      "C    1.785291\n",
      "D    0.000000\n",
      "F    4.000000\n",
      "dtype: float64\n",
      "6 4 46 34\n",
      "Operations\n",
      "See more at Histogramming and Discretization.\n",
      "In [68]: s = pd.Series(np.random.randint(0, 7, size=10))\n",
      "\n",
      "In [69]: s\n",
      "Out[69]: \n",
      "0    4\n",
      "1    2\n",
      "2    1\n",
      "3    2\n",
      "4    6\n",
      "5    4\n",
      "6    4\n",
      "7    6\n",
      "8    4\n",
      "9    4\n",
      "dtype: int64\n",
      "\n",
      "In [70]: s.value_counts()\n",
      "Out[70]: \n",
      "4    5\n",
      "6    2\n",
      "2    2\n",
      "1    1\n",
      "dtype: int64\n",
      "6 5 47 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations\n",
      "Series is equipped with a set of string processing methods in the str attribute that make it easy to operate on each element of the array, as in the code snippet below. Note that pattern-matching in str generally uses regular expressions by default (and in some cases always uses them). See more at Vectorized String Methods.\n",
      "In [71]: s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
      "\n",
      "In [72]: s.str.lower()\n",
      "Out[72]: \n",
      "0       a\n",
      "1       b\n",
      "2       c\n",
      "3    aaba\n",
      "4    baca\n",
      "5     NaN\n",
      "6    caba\n",
      "7     dog\n",
      "8     cat\n",
      "dtype: object\n",
      "6 13\n",
      "4 0 48 32\n",
      "Merge\n",
      "pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.See the Merging section.Concatenating pandas objects together with concat():\n",
      "In [73]: df = pd.DataFrame(np.random.randn(10, 4))\n",
      "\n",
      "In [74]: df\n",
      "Out[74]: \n",
      "          0         1         2         3\n",
      "0 -0.548702  1.467327 -1.015962 -0.483075\n",
      "1  1.637550 -1.217659 -0.291519 -1.745505\n",
      "2 -0.263952  0.991460 -0.919069  0.266046\n",
      "3 -0.709661  1.669052  1.037882 -1.705775\n",
      "4 -0.919854 -0.042379  1.247642 -0.009920\n",
      "5  0.290213  0.495767  0.362949  1.548106\n",
      "6 -1.131345 -0.089329  0.337863 -0.945867\n",
      "7 -0.932132  1.956030  0.017587 -0.016692\n",
      "8 -0.575247  0.254161 -1.143704  0.215897\n",
      "9  1.193555 -0.077118 -0.408530 -0.862495\n",
      "\n",
      "# break it into pieces\n",
      "In [75]: pieces = [df[:3], df[3:7], df[7:]]\n",
      "\n",
      "In [76]: pd.concat(pieces)\n",
      "Out[76]: \n",
      "          0         1         2         3\n",
      "0 -0.548702  1.467327 -1.015962 -0.483075\n",
      "1  1.637550 -1.217659 -0.291519 -1.745505\n",
      "2 -0.263952  0.991460 -0.919069  0.266046\n",
      "3 -0.709661  1.669052  1.037882 -1.705775\n",
      "4 -0.919854 -0.042379  1.247642 -0.009920\n",
      "5  0.290213  0.495767  0.362949  1.548106\n",
      "6 -1.131345 -0.089329  0.337863 -0.945867\n",
      "7 -0.932132  1.956030  0.017587 -0.016692\n",
      "8 -0.575247  0.254161 -1.143704  0.215897\n",
      "9  1.193555 -0.077118 -0.408530 -0.862495\n",
      "4 1 49 31\n",
      "Merge\n",
      "SQL style merges. See the Database style joining section.\n",
      "In [77]: left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
      "\n",
      "In [78]: right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
      "\n",
      "In [79]: left\n",
      "Out[79]: \n",
      "   key  lval\n",
      "0  foo     1\n",
      "1  foo     2\n",
      "\n",
      "In [80]: right\n",
      "Out[80]: \n",
      "   key  rval\n",
      "0  foo     4\n",
      "1  foo     5\n",
      "\n",
      "In [81]: pd.merge(left, right, on='key')\n",
      "Out[81]: \n",
      "   key  lval  rval\n",
      "0  foo     1     4\n",
      "1  foo     1     5\n",
      "2  foo     2     4\n",
      "3  foo     2     5\n",
      "4 2 50 30\n",
      "Merge\n",
      "Another example that can be given is:\n",
      "In [82]: left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
      "\n",
      "In [83]: right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
      "\n",
      "In [84]: left\n",
      "Out[84]: \n",
      "   key  lval\n",
      "0  foo     1\n",
      "1  bar     2\n",
      "\n",
      "In [85]: right\n",
      "Out[85]: \n",
      "   key  rval\n",
      "0  foo     4\n",
      "1  bar     5\n",
      "\n",
      "In [86]: pd.merge(left, right, on='key')\n",
      "Out[86]: \n",
      "   key  lval  rval\n",
      "0  foo     1     4\n",
      "1  bar     2     5\n",
      "4 3 51 29\n",
      "Merge\n",
      "Append rows to a dataframe. See the Appending section.\n",
      "In [87]: df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])\n",
      "\n",
      "In [88]: df\n",
      "Out[88]: \n",
      "          A         B         C         D\n",
      "0  1.346061  1.511763  1.627081 -0.990582\n",
      "1 -0.441652  1.211526  0.268520  0.024580\n",
      "2 -1.577585  0.396823 -0.105381 -0.532532\n",
      "3  1.453749  1.208843 -0.080952 -0.264610\n",
      "4 -0.727965 -0.589346  0.339969 -0.693205\n",
      "5 -0.339355  0.593616  0.884345  1.591431\n",
      "6  0.141809  0.220390  0.435589  0.192451\n",
      "7 -0.096701  0.803351  1.715071 -0.708758\n",
      "\n",
      "In [89]: s = df.iloc[3]\n",
      "\n",
      "In [90]: df.append(s, ignore_index=True)\n",
      "Out[90]: \n",
      "          A         B         C         D\n",
      "0  1.346061  1.511763  1.627081 -0.990582\n",
      "1 -0.441652  1.211526  0.268520  0.024580\n",
      "2 -1.577585  0.396823 -0.105381 -0.532532\n",
      "3  1.453749  1.208843 -0.080952 -0.264610\n",
      "4 -0.727965 -0.589346  0.339969 -0.693205\n",
      "5 -0.339355  0.593616  0.884345  1.591431\n",
      "6  0.141809  0.220390  0.435589  0.192451\n",
      "7 -0.096701  0.803351  1.715071 -0.708758\n",
      "8  1.453749  1.208843 -0.080952 -0.264610\n",
      "7 13\n",
      "3 0 52 28\n",
      "Grouping\n",
      "By “group by” we are referring to a process involving one or more of the following steps:See the Grouping section.\n",
      "In [91]: df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
      "   ....:                          'foo', 'bar', 'foo', 'foo'],\n",
      "   ....:                    'B': ['one', 'one', 'two', 'three',\n",
      "   ....:                          'two', 'two', 'one', 'three'],\n",
      "   ....:                    'C': np.random.randn(8),\n",
      "   ....:                    'D': np.random.randn(8)})\n",
      "   ....: \n",
      "\n",
      "In [92]: df\n",
      "Out[92]: \n",
      "     A      B         C         D\n",
      "0  foo    one -1.202872 -0.055224\n",
      "1  bar    one -1.814470  2.395985\n",
      "2  foo    two  1.018601  1.552825\n",
      "3  bar  three -0.595447  0.166599\n",
      "4  foo    two  1.395433  0.047609\n",
      "5  bar    two -0.392670 -0.136473\n",
      "6  foo    one  0.007207 -0.561757\n",
      "7  foo  three  1.928123 -1.623033\n",
      "3 1 53 27\n",
      "Grouping\n",
      "Grouping and then applying the sum() function to the resulting groups.\n",
      "In [93]: df.groupby('A').sum()\n",
      "Out[93]: \n",
      "            C        D\n",
      "A                     \n",
      "bar -2.802588  2.42611\n",
      "foo  3.146492 -0.63958\n",
      "3 2 54 26\n",
      "Grouping\n",
      "Grouping by multiple columns forms a hierarchical index, and again we can apply the sum function.\n",
      "In [94]: df.groupby(['A', 'B']).sum()\n",
      "Out[94]: \n",
      "                  C         D\n",
      "A   B                        \n",
      "bar one   -1.814470  2.395985\n",
      "    three -0.595447  0.166599\n",
      "    two   -0.392670 -0.136473\n",
      "foo one   -1.195665 -0.616981\n",
      "    three  1.928123 -1.623033\n",
      "    two    2.414034  1.600434\n",
      "8 13\n",
      "5 0 55 25\n",
      "Reshaping\n",
      "See the sections on Hierarchical Indexing and Reshaping.\n",
      "In [95]: tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
      "   ....:                      'foo', 'foo', 'qux', 'qux'],\n",
      "   ....:                     ['one', 'two', 'one', 'two',\n",
      "   ....:                      'one', 'two', 'one', 'two']]))\n",
      "   ....: \n",
      "\n",
      "In [96]: index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
      "\n",
      "In [97]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n",
      "\n",
      "In [98]: df2 = df[:4]\n",
      "\n",
      "In [99]: df2\n",
      "Out[99]: \n",
      "                     A         B\n",
      "first second                    \n",
      "bar   one     0.029399 -0.542108\n",
      "      two     0.282696 -0.087302\n",
      "baz   one    -1.575170  1.771208\n",
      "      two     0.816482  1.100230\n",
      "5 1 56 24\n",
      "Reshaping\n",
      "The stack() method “compresses” a level in the DataFrame’s columns.\n",
      "In [100]: stacked = df2.stack()\n",
      "\n",
      "In [101]: stacked\n",
      "Out[101]: \n",
      "first  second   \n",
      "bar    one     A    0.029399\n",
      "               B   -0.542108\n",
      "       two     A    0.282696\n",
      "               B   -0.087302\n",
      "baz    one     A   -1.575170\n",
      "               B    1.771208\n",
      "       two     A    0.816482\n",
      "               B    1.100230\n",
      "dtype: float64\n",
      "5 2 57 23\n",
      "Reshaping\n",
      "With a “stacked” DataFrame or Series (having a MultiIndex as the index), the inverse operation of stack() is unstack(), which by default unstacks the last level:\n",
      "In [102]: stacked.unstack()\n",
      "Out[102]: \n",
      "                     A         B\n",
      "first second                    \n",
      "bar   one     0.029399 -0.542108\n",
      "      two     0.282696 -0.087302\n",
      "baz   one    -1.575170  1.771208\n",
      "      two     0.816482  1.100230\n",
      "\n",
      "In [103]: stacked.unstack(1)\n",
      "Out[103]: \n",
      "second        one       two\n",
      "first                      \n",
      "bar   A  0.029399  0.282696\n",
      "      B -0.542108 -0.087302\n",
      "baz   A -1.575170  0.816482\n",
      "      B  1.771208  1.100230\n",
      "\n",
      "In [104]: stacked.unstack(0)\n",
      "Out[104]: \n",
      "first          bar       baz\n",
      "second                      \n",
      "one    A  0.029399 -1.575170\n",
      "       B -0.542108  1.771208\n",
      "two    A  0.282696  0.816482\n",
      "       B -0.087302  1.100230\n",
      "5 3 58 22\n",
      "Reshaping\n",
      "See the section on Pivot Tables.\n",
      "In [105]: df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
      "   .....:                    'B': ['A', 'B', 'C'] * 4,\n",
      "   .....:                    'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
      "   .....:                    'D': np.random.randn(12),\n",
      "   .....:                    'E': np.random.randn(12)})\n",
      "   .....: \n",
      "\n",
      "In [106]: df\n",
      "Out[106]: \n",
      "        A  B    C         D         E\n",
      "0     one  A  foo  1.418757 -0.179666\n",
      "1     one  B  foo -1.879024  1.291836\n",
      "2     two  C  foo  0.536826 -0.009614\n",
      "3   three  A  bar  1.006160  0.392149\n",
      "4     one  B  bar -0.029716  0.264599\n",
      "5     one  C  bar -1.146178 -0.057409\n",
      "6     two  A  foo  0.100900 -1.425638\n",
      "7   three  B  foo -1.035018  1.024098\n",
      "8     one  C  foo  0.314665 -0.106062\n",
      "9     one  A  bar -0.773723  1.824375\n",
      "10    two  B  bar -1.170653  0.595974\n",
      "11  three  C  bar  0.648740  1.167115\n",
      "5 4 59 21\n",
      "Reshaping\n",
      "We can produce pivot tables from this data very easily:\n",
      "In [107]: pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])\n",
      "Out[107]: \n",
      "C             bar       foo\n",
      "A     B                    \n",
      "one   A -0.773723  1.418757\n",
      "      B -0.029716 -1.879024\n",
      "      C -1.146178  0.314665\n",
      "three A  1.006160       NaN\n",
      "      B       NaN -1.035018\n",
      "      C  0.648740       NaN\n",
      "two   A       NaN  0.100900\n",
      "      B -1.170653       NaN\n",
      "      C       NaN  0.536826\n",
      "9 13\n",
      "5 0 60 20\n",
      "Time Series\n",
      "pandas has simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data). This is extremely common in, but not limited to, financial applications. See the Time Series section.\n",
      "In [108]: rng = pd.date_range('1/1/2012', periods=100, freq='S')\n",
      "\n",
      "In [109]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
      "\n",
      "In [110]: ts.resample('5Min').sum()\n",
      "Out[110]: \n",
      "2012-01-01    25083\n",
      "Freq: 5T, dtype: int64\n",
      "5 1 61 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series\n",
      "Time zone representation:\n",
      "In [111]: rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\n",
      "\n",
      "In [112]: ts = pd.Series(np.random.randn(len(rng)), rng)\n",
      "\n",
      "In [113]: ts\n",
      "Out[113]: \n",
      "2012-03-06    0.464000\n",
      "2012-03-07    0.227371\n",
      "2012-03-08   -0.496922\n",
      "2012-03-09    0.306389\n",
      "2012-03-10   -2.290613\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "In [114]: ts_utc = ts.tz_localize('UTC')\n",
      "\n",
      "In [115]: ts_utc\n",
      "Out[115]: \n",
      "2012-03-06 00:00:00+00:00    0.464000\n",
      "2012-03-07 00:00:00+00:00    0.227371\n",
      "2012-03-08 00:00:00+00:00   -0.496922\n",
      "2012-03-09 00:00:00+00:00    0.306389\n",
      "2012-03-10 00:00:00+00:00   -2.290613\n",
      "Freq: D, dtype: float64\n",
      "5 2 62 18\n",
      "Time Series\n",
      "Converting to another time zone:\n",
      "In [116]: ts_utc.tz_convert('US/Eastern')\n",
      "Out[116]: \n",
      "2012-03-05 19:00:00-05:00    0.464000\n",
      "2012-03-06 19:00:00-05:00    0.227371\n",
      "2012-03-07 19:00:00-05:00   -0.496922\n",
      "2012-03-08 19:00:00-05:00    0.306389\n",
      "2012-03-09 19:00:00-05:00   -2.290613\n",
      "Freq: D, dtype: float64\n",
      "5 3 63 17\n",
      "Time Series\n",
      "Converting between time span representations:\n",
      "In [117]: rng = pd.date_range('1/1/2012', periods=5, freq='M')\n",
      "\n",
      "In [118]: ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
      "\n",
      "In [119]: ts\n",
      "Out[119]: \n",
      "2012-01-31   -1.134623\n",
      "2012-02-29   -1.561819\n",
      "2012-03-31   -0.260838\n",
      "2012-04-30    0.281957\n",
      "2012-05-31    1.523962\n",
      "Freq: M, dtype: float64\n",
      "\n",
      "In [120]: ps = ts.to_period()\n",
      "\n",
      "In [121]: ps\n",
      "Out[121]: \n",
      "2012-01   -1.134623\n",
      "2012-02   -1.561819\n",
      "2012-03   -0.260838\n",
      "2012-04    0.281957\n",
      "2012-05    1.523962\n",
      "Freq: M, dtype: float64\n",
      "\n",
      "In [122]: ps.to_timestamp()\n",
      "Out[122]: \n",
      "2012-01-01   -1.134623\n",
      "2012-02-01   -1.561819\n",
      "2012-03-01   -0.260838\n",
      "2012-04-01    0.281957\n",
      "2012-05-01    1.523962\n",
      "Freq: MS, dtype: float64\n",
      "5 4 64 16\n",
      "Time Series\n",
      "Converting between period and timestamp enables some convenient arithmetic functions to be used. In the following example, we convert a quarterly frequency with year ending in November to 9am of the end of the month following the quarter end:\n",
      "In [123]: prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\n",
      "\n",
      "In [124]: ts = pd.Series(np.random.randn(len(prng)), prng)\n",
      "\n",
      "In [125]: ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9\n",
      "\n",
      "In [126]: ts.head()\n",
      "Out[126]: \n",
      "1990-03-01 09:00   -0.902937\n",
      "1990-06-01 09:00    0.068159\n",
      "1990-09-01 09:00   -0.057873\n",
      "1990-12-01 09:00   -0.368204\n",
      "1991-03-01 09:00   -1.144073\n",
      "Freq: H, dtype: float64\n",
      "10 13\n",
      "6 0 65 15\n",
      "Categoricals\n",
      "pandas can include categorical data in a DataFrame. For full docs, see the categorical introduction and the API documentation.\n",
      "In [127]: df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n",
      "   .....:                    \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n",
      "   .....: \n",
      "6 1 66 14\n",
      "Categoricals\n",
      "Convert the raw grades to a categorical data type.\n",
      "In [128]: df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n",
      "\n",
      "In [129]: df[\"grade\"]\n",
      "Out[129]: \n",
      "0    a\n",
      "1    b\n",
      "2    b\n",
      "3    a\n",
      "4    a\n",
      "5    e\n",
      "Name: grade, dtype: category\n",
      "Categories (3, object): [a, b, e]\n",
      "6 2 67 13\n",
      "Categoricals\n",
      "Rename the categories to more meaningful names (assigning to Series.cat.categories is inplace!).\n",
      "In [130]: df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]\n",
      "6 3 68 12\n",
      "Categoricals\n",
      "Reorder the categories and simultaneously add the missing categories (methods under Series .cat return a new Series by default).\n",
      "In [131]: df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\",\n",
      "   .....:                                               \"good\", \"very good\"])\n",
      "   .....: \n",
      "\n",
      "In [132]: df[\"grade\"]\n",
      "Out[132]: \n",
      "0    very good\n",
      "1         good\n",
      "2         good\n",
      "3    very good\n",
      "4    very good\n",
      "5     very bad\n",
      "Name: grade, dtype: category\n",
      "Categories (5, object): [very bad, bad, medium, good, very good]\n",
      "6 4 69 11\n",
      "Categoricals\n",
      "Sorting is per order in the categories, not lexical order.\n",
      "In [133]: df.sort_values(by=\"grade\")\n",
      "Out[133]: \n",
      "   id raw_grade      grade\n",
      "5   6         e   very bad\n",
      "1   2         b       good\n",
      "2   3         b       good\n",
      "0   1         a  very good\n",
      "3   4         a  very good\n",
      "4   5         a  very good\n",
      "6 5 70 10\n",
      "Categoricals\n",
      "Grouping by a categorical column also shows empty categories.\n",
      "In [134]: df.groupby(\"grade\").size()\n",
      "Out[134]: \n",
      "grade\n",
      "very bad     1\n",
      "bad          0\n",
      "medium       0\n",
      "good         2\n",
      "very good    3\n",
      "dtype: int64\n",
      "11 13\n",
      "2 0 71 9\n",
      "Plotting\n",
      "See the Plotting docs.\n",
      "In [135]: ts = pd.Series(np.random.randn(1000),\n",
      "   .....:                index=pd.date_range('1/1/2000', periods=1000))\n",
      "   .....: \n",
      "\n",
      "In [136]: ts = ts.cumsum()\n",
      "\n",
      "In [137]: ts.plot()\n",
      "Out[137]: <matplotlib.axes._subplots.AxesSubplot at 0x7f2b5771ac88>\n",
      "2 1 72 8\n",
      "Plotting\n",
      "On a DataFrame, the plot() method is a convenience to plot all of the columns with labels:\n",
      "In [138]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,\n",
      "   .....:                   columns=['A', 'B', 'C', 'D'])\n",
      "   .....: \n",
      "\n",
      "In [139]: df = df.cumsum()\n",
      "\n",
      "In [140]: plt.figure()\n",
      "Out[140]: <Figure size 640x480 with 0 Axes>\n",
      "\n",
      "In [141]: df.plot()\n",
      "Out[141]: <matplotlib.axes._subplots.AxesSubplot at 0x7f2b53a2d7f0>\n",
      "\n",
      "In [142]: plt.legend(loc='best')\n",
      "Out[142]: <matplotlib.legend.Legend at 0x7f2b539728d0>\n",
      "12 13\n",
      "6 0 73 7\n",
      "Getting Data In/Out\n",
      "Writing to a csv file.\n",
      "In [143]: df.to_csv('foo.csv')\n",
      "6 1 74 6\n",
      "Getting Data In/Out\n",
      "Reading from a csv file.\n",
      "In [144]: pd.read_csv('foo.csv')\n",
      "Out[144]: \n",
      "     Unnamed: 0          A          B         C          D\n",
      "0    2000-01-01   0.266457  -0.399641 -0.219582   1.186860\n",
      "1    2000-01-02  -1.170732  -0.345873  1.653061  -0.282953\n",
      "2    2000-01-03  -1.734933   0.530468  2.060811  -0.515536\n",
      "3    2000-01-04  -1.555121   1.452620  0.239859  -1.156896\n",
      "4    2000-01-05   0.578117   0.511371  0.103552  -2.428202\n",
      "5    2000-01-06   0.478344   0.449933 -0.741620  -1.962409\n",
      "6    2000-01-07   1.235339  -0.091757 -1.543861  -1.084753\n",
      "..          ...        ...        ...       ...        ...\n",
      "993  2002-09-20 -10.628548  -9.153563 -7.883146  28.313940\n",
      "994  2002-09-21 -10.390377  -8.727491 -6.399645  30.914107\n",
      "995  2002-09-22  -8.985362  -8.485624 -4.669462  31.367740\n",
      "996  2002-09-23  -9.558560  -8.781216 -4.499815  30.518439\n",
      "997  2002-09-24  -9.902058  -9.340490 -4.386639  30.105593\n",
      "998  2002-09-25 -10.216020  -9.480682 -3.933802  29.758560\n",
      "999  2002-09-26 -11.856774 -10.671012 -3.216025  29.369368\n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "6 2 75 5\n",
      "Getting Data In/Out\n",
      "Reading and writing to HDFStores.Writing to a HDF5 Store.\n",
      "In [145]: df.to_hdf('foo.h5', 'df')\n",
      "6 3 76 4\n",
      "Getting Data In/Out\n",
      "Reading from a HDF5 Store.\n",
      "In [146]: pd.read_hdf('foo.h5', 'df')\n",
      "Out[146]: \n",
      "                    A          B         C          D\n",
      "2000-01-01   0.266457  -0.399641 -0.219582   1.186860\n",
      "2000-01-02  -1.170732  -0.345873  1.653061  -0.282953\n",
      "2000-01-03  -1.734933   0.530468  2.060811  -0.515536\n",
      "2000-01-04  -1.555121   1.452620  0.239859  -1.156896\n",
      "2000-01-05   0.578117   0.511371  0.103552  -2.428202\n",
      "2000-01-06   0.478344   0.449933 -0.741620  -1.962409\n",
      "2000-01-07   1.235339  -0.091757 -1.543861  -1.084753\n",
      "...               ...        ...       ...        ...\n",
      "2002-09-20 -10.628548  -9.153563 -7.883146  28.313940\n",
      "2002-09-21 -10.390377  -8.727491 -6.399645  30.914107\n",
      "2002-09-22  -8.985362  -8.485624 -4.669462  31.367740\n",
      "2002-09-23  -9.558560  -8.781216 -4.499815  30.518439\n",
      "2002-09-24  -9.902058  -9.340490 -4.386639  30.105593\n",
      "2002-09-25 -10.216020  -9.480682 -3.933802  29.758560\n",
      "2002-09-26 -11.856774 -10.671012 -3.216025  29.369368\n",
      "\n",
      "[1000 rows x 4 columns]\n",
      "6 4 77 3\n",
      "Getting Data In/Out\n",
      "Reading and writing to MS Excel.Writing to an excel file.\n",
      "In [147]: df.to_excel('foo.xlsx', sheet_name='Sheet1')\n",
      "6 5 78 2\n",
      "Getting Data In/Out\n",
      "Reading from an excel file.\n",
      "In [148]: pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])\n",
      "Out[148]: \n",
      "    Unnamed: 0          A          B         C          D\n",
      "0   2000-01-01   0.266457  -0.399641 -0.219582   1.186860\n",
      "1   2000-01-02  -1.170732  -0.345873  1.653061  -0.282953\n",
      "2   2000-01-03  -1.734933   0.530468  2.060811  -0.515536\n",
      "3   2000-01-04  -1.555121   1.452620  0.239859  -1.156896\n",
      "4   2000-01-05   0.578117   0.511371  0.103552  -2.428202\n",
      "5   2000-01-06   0.478344   0.449933 -0.741620  -1.962409\n",
      "6   2000-01-07   1.235339  -0.091757 -1.543861  -1.084753\n",
      "..         ...        ...        ...       ...        ...\n",
      "993 2002-09-20 -10.628548  -9.153563 -7.883146  28.313940\n",
      "994 2002-09-21 -10.390377  -8.727491 -6.399645  30.914107\n",
      "995 2002-09-22  -8.985362  -8.485624 -4.669462  31.367740\n",
      "996 2002-09-23  -9.558560  -8.781216 -4.499815  30.518439\n",
      "997 2002-09-24  -9.902058  -9.340490 -4.386639  30.105593\n",
      "998 2002-09-25 -10.216020  -9.480682 -3.933802  29.758560\n",
      "999 2002-09-26 -11.856774 -10.671012 -3.216025  29.369368\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "title = []\n",
    "descriptions = []\n",
    "codeBlock = []\n",
    "url_word = []\n",
    "url_attachment = []\n",
    "df_learn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_total = {}\n",
    "for x in range(len(title)):\n",
    "    json_d = {'Title':title[x],'Text':descriptions[x],'Code_snippet':codeBlock[x],'Url':url_word[x],'Attachment_Url':url_attachment[x]}\n",
    "    json_total[x] = json_d\n",
    "    json_total.update(json_d)\n",
    "\n",
    "\n",
    "with open('../datasets/parrafos_df.json', 'w') as outfile:\n",
    "    json.dump(json_total, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 'Operations',\n",
       " 'Text': 'See the Basic section on Binary Ops.Operations in general exclude missing data.Performing a descriptive statistic:',\n",
       " 'Code_snippet': 'In [61]: df.mean()\\nOut[61]: \\nA   -0.004474\\nB   -0.383981\\nC   -0.687758\\nD    5.000000\\nF    3.000000\\ndtype: float64',\n",
       " 'Url': 'https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html',\n",
       " 'Attachment_Url': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_total[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In [3]: s = pd.Series([1, 3, 5, np.nan, 6, 8])\\n\\nIn [4]: s\\nOut[4]: \\n0    1.0\\n1    3.0\\n2    5.0\\n3    NaN\\n4    6.0\\n5    8.0\\ndtype: float64'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeBlock[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
