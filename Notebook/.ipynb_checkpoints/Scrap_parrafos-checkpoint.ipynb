{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parrafos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "\n",
    "driver = None\n",
    "\n",
    "def load_driver(url):\n",
    "    \"\"\" Logging into our own profile \"\"\"\n",
    "\n",
    "    try:\n",
    "        global driver\n",
    "\n",
    "        options = Options()\n",
    "\n",
    "        #  Code to disable notifications pop up of Chrome Browser\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--disable-infobars\")\n",
    "        options.add_argument(\"--mute-audio\")\n",
    "        # options.add_argument(\"headless\")\n",
    "\n",
    "        try:\n",
    "            platform_ = platform.system().lower()\n",
    "            print(platform_)\n",
    "            if platform_ in ['linux', 'darwin']:\n",
    "                print(webdriver.Chrome(executable_path=\"./chromedriver\", options=options))\n",
    "                driver = webdriver.Chrome(executable_path=\"./chromedriver\", options=options)\n",
    "            else:\n",
    "                driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\", options=options)\n",
    "        except:\n",
    "            print(\"Kindly replace the Chrome Web Driver with the latest one from\"\n",
    "                  \"http://chromedriver.chromium.org/downloads\"\n",
    "                  \"\\nYour OS: {}\".format(platform_)\n",
    "                 )\n",
    "            exit()\n",
    "\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"There's some error in log in.\")\n",
    "        print(sys.exc_info()[0])\n",
    "        print(e)\n",
    "        exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sk_learn():\n",
    "    global words,descriptions,code,url_word,url_attachment\n",
    "    url = \"https://scikit-learn.org/stable/user_guide.html\"\n",
    "    load_driver(url)\n",
    "    for i in range(1,8):\n",
    "        _block = driver.find_elements_by_xpath(\"//li[@class='toctree-l1'][\"+str(i)+\"]\")\n",
    "        _mainSection = driver.find_elements_by_xpath(\"//li[@class='toctree-l1'][\"+str(i)+\"]/ul/li/a\")                                       \n",
    "        for k in range(len(_mainSection)):\n",
    "            _mainSection = driver.find_elements_by_xpath(\"//li[@class='toctree-l1'][\"+str(i)+\"]/ul/li/a\")    \n",
    "            sect = _mainSection[k]\n",
    "            driver.get(sect.get_attribute(\"href\"))\n",
    "            _titles = driver.find_elements_by_xpath(\"//h2\")\n",
    "            for j in range(1,len(_titles)+1):\n",
    "                _textP = driver.find_elements_by_xpath(\"//div[@class='section']/div[@class='section'][\"+str(j)+\"]/p\")\n",
    "                _title = driver.find_element_by_xpath(\"//h2[\"+str(j)+\"]\")\n",
    "                _code = driver.find_elements_by_xpath(\"//div[@class='section']/div[@class='section'][\"+str(j)+\"]//pre\")\n",
    "                _img = driver.find_elements_by_xpath(\"//div[@class='section']/div[@class='section'][\"+str(j)+\"]//img\")\n",
    "                _text = \"\"\n",
    "                _codeText = \"\"\n",
    "                _imgSrc = []\n",
    "                for p in _textP:\n",
    "                    _text += p.text + \"\\n\"\n",
    "                for code in _code:\n",
    "                    _codeText += code.text\n",
    "                for img in _img:\n",
    "                    _imgSrc.append(img.get_attribute(\"src\"))\n",
    "                print(_title,_textP,_code,_img)\n",
    "            driver.back()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darwin\n",
      "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"dc21fe36e88bf56178638f2b1ba3ef09\")>\n"
     ]
    },
    {
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: Unable to locate an element with the xpath expression //h21] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//h21]' is not a valid XPath expression.\n  (Session info: chrome=74.0.3729.131)\n  (Driver info: chromedriver=72.0.3626.69 (3c16f8a135abc0d4da2dff33804db79b849a7c38),platform=Mac OS X 10.14.3 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-cf7fe022864a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msk_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-50ce8bf09e5a>\u001b[0m in \u001b[0;36msk_learn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_titles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0m_textP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//div[@class='section']/div[@class='section'][\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"]/p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0m_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//h2\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0m_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//div[@class='section']/div[@class='section'][\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"]//pre\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0m_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//div[@class='section']/div[@class='section'][\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"]//img\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidSelectorException\u001b[0m: Message: invalid selector: Unable to locate an element with the xpath expression //h21] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//h21]' is not a valid XPath expression.\n  (Session info: chrome=74.0.3729.131)\n  (Driver info: chromedriver=72.0.3626.69 (3c16f8a135abc0d4da2dff33804db79b849a7c38),platform=Mac OS X 10.14.3 x86_64)\n"
     ]
    }
   ],
   "source": [
    "sk_learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def guide2_ml():\n",
    "    global words,descriptions,url_word,url_attachment\n",
    "    url = \"https://www.pyimagesearch.com/2019/01/14/machine-learning-in-python/\"\n",
    "    load_driver(url)\n",
    "    \n",
    "    for i in range(3,20):\n",
    "        text = []\n",
    "        img_att = []\n",
    "        print(i)\n",
    "        _parragraph =driver.find_elements_by_xpath(\" //section[@id='main']//*[preceding::h3[\"+str(i+1)+\"] and following::h3[\"+str(14-i)+\"]]\")\n",
    "\n",
    "        for p in _parragraph:\n",
    "            if(p.get_attribute(\"src\") == None):\n",
    "                #No es imagen\n",
    "                text.append(p.text)\n",
    "            else:\n",
    "                img_att.append(p.get_attribute(\"src\"))\n",
    "        _word =driver.find_element_by_xpath(\" //h3[\"+str(i+1)+\"]\")\n",
    "        words.append(_word.text)\n",
    "        descriptions.append(text)\n",
    "        url_word.append(driver.current_url)\n",
    "        url_attachment.append(img_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Machine learning is learning based on experience. As an example, it is like a person who learns to play chess through observation as others play. In this way, computers can be programmed through the provision of information which they are trained, acquiring the ability to identify elements or their characteristics with high probability.',\n",
       " 'Machine learning is learning based on experience.',\n",
       " 'First of all, you need to know that there are various stages of machine learning:',\n",
       " 'stages of machine learning',\n",
       " 'data collection\\ndata sorting\\ndata analysis\\nalgorithm development\\nchecking algorithm generated\\nthe use of an algorithm to further conclusions',\n",
       " 'data collection',\n",
       " 'data sorting',\n",
       " 'data analysis',\n",
       " 'algorithm development',\n",
       " 'checking algorithm generated',\n",
       " 'the use of an algorithm to further conclusions',\n",
       " 'To look for patterns, various algorithms are used, which are divided into two groups:',\n",
       " 'two groups',\n",
       " 'Unsupervised learning\\nSupervised learning',\n",
       " 'Unsupervised learning',\n",
       " 'Supervised learning',\n",
       " 'With unsupervised learning, your machine receives only a set of input data. Thereafter, the machine is up to determine the relationship between the entered data and any other hypothetical data. Unlike supervised learning, where the machine is provided with some verification data for learning, independent Unsupervised learning implies that the computer itself will find patterns and relationships between different data sets. Unsupervised learning can be further divided into clustering and association.',\n",
       " 'unsupervised learning',\n",
       " 'Supervised learning implies the computer ability to recognize elements based on the provided samples. The computer studies it and develops the ability to recognize new data based on this data. For example, you can train your computer to filter spam messages based on previously received information.',\n",
       " 'Supervised learning',\n",
       " 'Some Supervised learning algorithms include:',\n",
       " 'Supervised learning algorithms',\n",
       " 'Decision trees\\nSupport-vector machine\\nNaive Bayes classifier\\nk-nearest neighbors\\nlinear regression',\n",
       " 'Decision trees',\n",
       " 'Support-vector machine',\n",
       " 'Naive Bayes classifier',\n",
       " 'k-nearest neighbors',\n",
       " 'linear regression']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darwin\n",
      "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"e2151f416adbd62504725488d3ad41e6\")>\n",
      "darwin\n",
      "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"f64027ec4f6bdef08e23f2a5bd350973\")>\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\" //h3[20]\"}\n  (Session info: chrome=74.0.3729.131)\n  (Driver info: chromedriver=72.0.3626.69 (3c16f8a135abc0d4da2dff33804db79b849a7c38),platform=Mac OS X 10.14.3 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-405f13595450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl_attachment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mguide_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mguide2_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-72fed40acc6b>\u001b[0m in \u001b[0;36mguide2_ml\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mimg_att\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"src\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0m_word\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" //h3[\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdescriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/envs/WebScraping/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\" //h3[20]\"}\n  (Session info: chrome=74.0.3729.131)\n  (Driver info: chromedriver=72.0.3626.69 (3c16f8a135abc0d4da2dff33804db79b849a7c38),platform=Mac OS X 10.14.3 x86_64)\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "descriptions = []\n",
    "url_word = []\n",
    "url_attachment = []\n",
    "guide_ml()\n",
    "guide2_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_total = {}\n",
    "for x in range(len(words)):\n",
    "    json_d = {'Title':words[x],'Text':descriptions[x],'Url':url_word[x],'Attachment_Url':url_attachment[x]}\n",
    "    json_total[x] = json_d\n",
    "    json_total.update(json_d)\n",
    "\n",
    "\n",
    "with open('../datasets/parrafos.json', 'w') as outfile:\n",
    "    json.dump(json_total, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Be sure to grab the “Downloads” associated with this blog post.',\n",
       " '“Downloads”',\n",
       " '“Downloads”',\n",
       " 'From there you can unzip the archive and inspect the contents:',\n",
       " 'Machine Learning in Python\\nShell\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n$ tree --dirsfirst --filelimit 10\\n.\\n├── 3scenes\\n│   ├── coast [360 entries]\\n│   ├── forest [328 entries]\\n│   └── highway [260 entries]\\n├── classify_iris.py\\n├── classify_images.py\\n├── nn_iris.py\\n└── basic_cnn.py\\n 4 directories, 4 files',\n",
       " 'Machine Learning in Python\\nShell',\n",
       " 'Machine Learning in Python',\n",
       " 'Shell',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Shell',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n$ tree --dirsfirst --filelimit 10\\n.\\n├── 3scenes\\n│   ├── coast [360 entries]\\n│   ├── forest [328 entries]\\n│   └── highway [260 entries]\\n├── classify_iris.py\\n├── classify_images.py\\n├── nn_iris.py\\n└── basic_cnn.py\\n 4 directories, 4 files',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n$ tree --dirsfirst --filelimit 10\\n.\\n├── 3scenes\\n│   ├── coast [360 entries]\\n│   ├── forest [328 entries]\\n│   └── highway [260 entries]\\n├── classify_iris.py\\n├── classify_images.py\\n├── nn_iris.py\\n└── basic_cnn.py\\n 4 directories, 4 files',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n$ tree --dirsfirst --filelimit 10\\n.\\n├── 3scenes\\n│   ├── coast [360 entries]\\n│   ├── forest [328 entries]\\n│   └── highway [260 entries]\\n├── classify_iris.py\\n├── classify_images.py\\n├── nn_iris.py\\n└── basic_cnn.py\\n 4 directories, 4 files',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n$ tree --dirsfirst --filelimit 10\\n.\\n├── 3scenes\\n│   ├── coast [360 entries]\\n│   ├── forest [328 entries]\\n│   └── highway [260 entries]\\n├── classify_iris.py\\n├── classify_images.py\\n├── nn_iris.py\\n└── basic_cnn.py\\n 4 directories, 4 files',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '$ tree --dirsfirst --filelimit 10\\n.\\n├── 3scenes\\n│   ├── coast [360 entries]\\n│   ├── forest [328 entries]\\n│   └── highway [260 entries]\\n├── classify_iris.py\\n├── classify_images.py\\n├── nn_iris.py\\n└── basic_cnn.py\\n 4 directories, 4 files',\n",
       " '$ tree --dirsfirst --filelimit 10\\n.\\n├── 3scenes\\n│   ├── coast [360 entries]\\n│   ├── forest [328 entries]\\n│   └── highway [260 entries]\\n├── classify_iris.py\\n├── classify_images.py\\n├── nn_iris.py\\n└── basic_cnn.py\\n 4 directories, 4 files',\n",
       " '$ tree --dirsfirst --filelimit 10',\n",
       " '$',\n",
       " ' ',\n",
       " 'tree',\n",
       " ' ',\n",
       " '--',\n",
       " 'dirsfirst',\n",
       " ' ',\n",
       " '--',\n",
       " 'filelimit',\n",
       " ' ',\n",
       " '10',\n",
       " '.',\n",
       " '.',\n",
       " '├── 3scenes',\n",
       " ' ',\n",
       " '3scenes',\n",
       " '│   ├── coast [360 entries]',\n",
       " ' ',\n",
       " ' ',\n",
       " 'coast',\n",
       " ' ',\n",
       " '[',\n",
       " '360',\n",
       " ' ',\n",
       " 'entries',\n",
       " ']',\n",
       " '│   ├── forest [328 entries]',\n",
       " ' ',\n",
       " ' ',\n",
       " 'forest',\n",
       " ' ',\n",
       " '[',\n",
       " '328',\n",
       " ' ',\n",
       " 'entries',\n",
       " ']',\n",
       " '│   └── highway [260 entries]',\n",
       " ' ',\n",
       " ' ',\n",
       " 'highway',\n",
       " ' ',\n",
       " '[',\n",
       " '260',\n",
       " ' ',\n",
       " 'entries',\n",
       " ']',\n",
       " '├── classify_iris.py',\n",
       " ' ',\n",
       " 'classify_iris',\n",
       " '.py',\n",
       " '├── classify_images.py',\n",
       " ' ',\n",
       " 'classify_images',\n",
       " '.py',\n",
       " '├── nn_iris.py',\n",
       " ' ',\n",
       " 'nn_iris',\n",
       " '.py',\n",
       " '└── basic_cnn.py',\n",
       " ' ',\n",
       " 'basic_cnn',\n",
       " '.py',\n",
       " ' ',\n",
       " '4 directories, 4 files',\n",
       " '4',\n",
       " ' ',\n",
       " 'directories',\n",
       " ',',\n",
       " ' ',\n",
       " '4',\n",
       " ' ',\n",
       " 'files',\n",
       " 'The Iris dataset is built into scikit-learn. The 3-scenes dataset, however, is not. I’ve included it in the 3scenes/  directory and as you can see there are three subdirectories (classes) of images.',\n",
       " '3scenes/',\n",
       " '3scenes/',\n",
       " '3scenes',\n",
       " '/',\n",
       " 'We’ll be reviewing four Python machine learning scripts today:',\n",
       " 'classify_iris.py : Loads the Iris dataset and can apply any one of seven machine learning algorithms with a simple command line argument switch.\\nclassify_images.py : Gathers our image dataset (3-scenes) and applies any one of seven Python machine learning algorithms\\nnn_iris.py : Applies a simple multi-layer neural network to the Iris dataset\\nbasic_cnn.py : Builds a Convolutional Neural Network (CNN) and trains a model using the 3-scenes dataset',\n",
       " 'classify_iris.py : Loads the Iris dataset and can apply any one of seven machine learning algorithms with a simple command line argument switch.',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris',\n",
       " '.py',\n",
       " 'classify_images.py : Gathers our image dataset (3-scenes) and applies any one of seven Python machine learning algorithms',\n",
       " 'classify_images.py',\n",
       " 'classify_images.py',\n",
       " 'classify_images',\n",
       " '.py',\n",
       " 'nn_iris.py : Applies a simple multi-layer neural network to the Iris dataset',\n",
       " 'nn_iris.py',\n",
       " 'nn_iris.py',\n",
       " 'nn_iris',\n",
       " '.py',\n",
       " 'basic_cnn.py : Builds a Convolutional Neural Network (CNN) and trains a model using the 3-scenes dataset',\n",
       " 'basic_cnn.py',\n",
       " 'basic_cnn.py',\n",
       " 'basic_cnn',\n",
       " '.py',\n",
       " 'Implementing Python machine learning for numerical data',\n",
       " 'Figure 4: Over time, many statistical machine learning approaches have been developed. You can use this map from the scikit-learn team as a guide for the most popular methods. Expand.',\n",
       " '',\n",
       " 'Figure 4: Over time, many statistical machine learning approaches have been developed. You can use this map from the scikit-learn team as a guide for the most popular methods. Expand.',\n",
       " 'Figure 4:',\n",
       " 'map from the scikit-learn team',\n",
       " 'Expand',\n",
       " 'The first script we are going to implement is classify_iris.py  — this script will be used to spot-check machine learning algorithms on the Iris dataset.',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris',\n",
       " '.py',\n",
       " 'Once implemented, we’ll be able to use classify_iris.py  to run a suite of machine learning algorithms on the Iris dataset, look at the results, and decide on which algorithm works best for the project.',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris',\n",
       " '.py',\n",
       " 'Let’s get started — open up the classify_iris.py  file and insert the following code:',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris.py',\n",
       " 'classify_iris',\n",
       " '.py',\n",
       " 'Machine Learning in Python\\nPython\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.datasets import load_iris\\nimport argparse\\n # construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",\\n help=\"type of python machine learning model to use\")\\nargs = vars(ap.parse_args())',\n",
       " 'Machine Learning in Python\\nPython',\n",
       " 'Machine Learning in Python',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.datasets import load_iris\\nimport argparse\\n # construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",\\n help=\"type of python machine learning model to use\")\\nargs = vars(ap.parse_args())',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.datasets import load_iris\\nimport argparse\\n # construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",\\n help=\"type of python machine learning model to use\")\\nargs = vars(ap.parse_args())',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.datasets import load_iris\\nimport argparse\\n # construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",\\n help=\"type of python machine learning model to use\")\\nargs = vars(ap.parse_args())',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.datasets import load_iris\\nimport argparse\\n # construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",\\n help=\"type of python machine learning model to use\")\\nargs = vars(ap.parse_args())',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.datasets import load_iris\\nimport argparse\\n # construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",\\n help=\"type of python machine learning model to use\")\\nargs = vars(ap.parse_args())',\n",
       " '# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.datasets import load_iris\\nimport argparse\\n # construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",\\n help=\"type of python machine learning model to use\")\\nargs = vars(ap.parse_args())',\n",
       " '# import the necessary packages',\n",
       " '# import the necessary packages',\n",
       " 'from sklearn.neighbors import KNeighborsClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'neighbors ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'KNeighborsClassifier',\n",
       " 'from sklearn.naive_bayes import GaussianNB',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'naive_bayes ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'GaussianNB',\n",
       " 'from sklearn.linear_model import LogisticRegression',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'linear_model ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'LogisticRegression',\n",
       " 'from sklearn.svm import SVC',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'svm ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'SVC',\n",
       " 'from sklearn.tree import DecisionTreeClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'tree ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'DecisionTreeClassifier',\n",
       " 'from sklearn.ensemble import RandomForestClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'ensemble ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'RandomForestClassifier',\n",
       " 'from sklearn.neural_network import MLPClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'neural_network ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'MLPClassifier',\n",
       " 'from sklearn.model_selection import train_test_split',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'model_selection ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'train_test_split',\n",
       " 'from sklearn.metrics import classification_report',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'metrics ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'classification_report',\n",
       " 'from sklearn.datasets import load_iris',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'datasets ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'load_iris',\n",
       " 'import argparse',\n",
       " 'import',\n",
       " ' ',\n",
       " 'argparse',\n",
       " ' ',\n",
       " '# construct the argument parser and parse the arguments',\n",
       " '# construct the argument parser and parse the arguments',\n",
       " 'ap = argparse.ArgumentParser()',\n",
       " 'ap',\n",
       " ' ',\n",
       " '=',\n",
       " ' ',\n",
       " 'argparse',\n",
       " '.',\n",
       " 'ArgumentParser',\n",
       " '(',\n",
       " ')',\n",
       " 'ap.add_argument(\"-m\", \"--model\", type=str, default=\"knn\",',\n",
       " 'ap',\n",
       " '.',\n",
       " 'add_argument',\n",
       " '(',\n",
       " '\"-m\"',\n",
       " ',',\n",
       " ' ',\n",
       " '\"--model\"',\n",
       " ',',\n",
       " ' ',\n",
       " 'type',\n",
       " '=',\n",
       " 'str',\n",
       " ',',\n",
       " ' ',\n",
       " 'default',\n",
       " '=',\n",
       " '\"knn\"',\n",
       " ',',\n",
       " ' help=\"type of python machine learning model to use\")',\n",
       " ' ',\n",
       " 'help',\n",
       " '=',\n",
       " '\"type of python machine learning model to use\"',\n",
       " ')',\n",
       " 'args = vars(ap.parse_args())',\n",
       " 'args',\n",
       " ' ',\n",
       " '=',\n",
       " ' ',\n",
       " 'vars',\n",
       " '(',\n",
       " 'ap',\n",
       " '.',\n",
       " 'parse_args',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " 'Lines 2-12 import our required packages, specifically:',\n",
       " 'Lines 2-12',\n",
       " 'Our Python machine learning methods from scikit-learn (Lines 2-8)\\nA dataset splitting method used to separate our data into training and testing subsets (Line 9)\\nThe classification report utility from scikit-learn which will print a summarization of our machine learning results (Line 10)\\nOur Iris dataset, built into scikit-learn (Line 11)\\nA tool for command line argument parsing called argparse  (Line 12)',\n",
       " 'Our Python machine learning methods from scikit-learn (Lines 2-8)',\n",
       " 'Lines 2-8',\n",
       " 'A dataset splitting method used to separate our data into training and testing subsets (Line 9)',\n",
       " 'Line 9',\n",
       " 'The classification report utility from scikit-learn which will print a summarization of our machine learning results (Line 10)',\n",
       " 'Line 10',\n",
       " 'Our Iris dataset, built into scikit-learn (Line 11)',\n",
       " 'Line 11',\n",
       " 'A tool for command line argument parsing called argparse  (Line 12)',\n",
       " 'command line argument parsing',\n",
       " 'argparse',\n",
       " 'argparse',\n",
       " 'argparse',\n",
       " 'Line 12',\n",
       " 'Using argparse , let’s parse a single command line argument flag, --model  on Lines 15-18. The --model  switch allows us to choose from any of the following models:',\n",
       " 'argparse',\n",
       " 'argparse',\n",
       " 'argparse',\n",
       " '--model',\n",
       " '--model',\n",
       " '--',\n",
       " 'model',\n",
       " 'Lines 15-18',\n",
       " '--model',\n",
       " '--model',\n",
       " '--',\n",
       " 'model',\n",
       " 'Machine Learning in Python\\nPython\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n# define the dictionary of models our script can use, where the key\\n# to the dictionary is the name of the model (supplied via command\\n# line argument) and the value is the model itself\\nmodels = {\\n \"knn\": KNeighborsClassifier(n_neighbors=1),\\n \"naive_bayes\": GaussianNB(),\\n \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\\n \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\\n \"decision_tree\": DecisionTreeClassifier(),\\n \"random_forest\": RandomForestClassifier(n_estimators=100),\\n \"mlp\": MLPClassifier()\\n}',\n",
       " 'Machine Learning in Python\\nPython',\n",
       " 'Machine Learning in Python',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n# define the dictionary of models our script can use, where the key\\n# to the dictionary is the name of the model (supplied via command\\n# line argument) and the value is the model itself\\nmodels = {\\n \"knn\": KNeighborsClassifier(n_neighbors=1),\\n \"naive_bayes\": GaussianNB(),\\n \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\\n \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\\n \"decision_tree\": DecisionTreeClassifier(),\\n \"random_forest\": RandomForestClassifier(n_estimators=100),\\n \"mlp\": MLPClassifier()\\n}',\n",
       " '20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n# define the dictionary of models our script can use, where the key\\n# to the dictionary is the name of the model (supplied via command\\n# line argument) and the value is the model itself\\nmodels = {\\n \"knn\": KNeighborsClassifier(n_neighbors=1),\\n \"naive_bayes\": GaussianNB(),\\n \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\\n \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\\n \"decision_tree\": DecisionTreeClassifier(),\\n \"random_forest\": RandomForestClassifier(n_estimators=100),\\n \"mlp\": MLPClassifier()\\n}',\n",
       " '20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n# define the dictionary of models our script can use, where the key\\n# to the dictionary is the name of the model (supplied via command\\n# line argument) and the value is the model itself\\nmodels = {\\n \"knn\": KNeighborsClassifier(n_neighbors=1),\\n \"naive_bayes\": GaussianNB(),\\n \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\\n \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\\n \"decision_tree\": DecisionTreeClassifier(),\\n \"random_forest\": RandomForestClassifier(n_estimators=100),\\n \"mlp\": MLPClassifier()\\n}',\n",
       " '20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n# define the dictionary of models our script can use, where the key\\n# to the dictionary is the name of the model (supplied via command\\n# line argument) and the value is the model itself\\nmodels = {\\n \"knn\": KNeighborsClassifier(n_neighbors=1),\\n \"naive_bayes\": GaussianNB(),\\n \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\\n \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\\n \"decision_tree\": DecisionTreeClassifier(),\\n \"random_forest\": RandomForestClassifier(n_estimators=100),\\n \"mlp\": MLPClassifier()\\n}',\n",
       " '20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31',\n",
       " '20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '# define the dictionary of models our script can use, where the key\\n# to the dictionary is the name of the model (supplied via command\\n# line argument) and the value is the model itself\\nmodels = {\\n \"knn\": KNeighborsClassifier(n_neighbors=1),\\n \"naive_bayes\": GaussianNB(),\\n \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\\n \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\\n \"decision_tree\": DecisionTreeClassifier(),\\n \"random_forest\": RandomForestClassifier(n_estimators=100),\\n \"mlp\": MLPClassifier()\\n}',\n",
       " '# define the dictionary of models our script can use, where the key\\n# to the dictionary is the name of the model (supplied via command\\n# line argument) and the value is the model itself\\nmodels = {\\n \"knn\": KNeighborsClassifier(n_neighbors=1),\\n \"naive_bayes\": GaussianNB(),\\n \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\\n \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\\n \"decision_tree\": DecisionTreeClassifier(),\\n \"random_forest\": RandomForestClassifier(n_estimators=100),\\n \"mlp\": MLPClassifier()\\n}',\n",
       " '# define the dictionary of models our script can use, where the key',\n",
       " '# define the dictionary of models our script can use, where the key',\n",
       " '# to the dictionary is the name of the model (supplied via command',\n",
       " '# to the dictionary is the name of the model (supplied via command',\n",
       " '# line argument) and the value is the model itself',\n",
       " '# line argument) and the value is the model itself',\n",
       " 'models = {',\n",
       " 'models',\n",
       " ' ',\n",
       " '=',\n",
       " ' ',\n",
       " '{',\n",
       " ' \"knn\": KNeighborsClassifier(n_neighbors=1),',\n",
       " ' ',\n",
       " '\"knn\"',\n",
       " ':',\n",
       " ' ',\n",
       " 'KNeighborsClassifier',\n",
       " '(',\n",
       " 'n_neighbors',\n",
       " '=',\n",
       " '1',\n",
       " ')',\n",
       " ',',\n",
       " ' \"naive_bayes\": GaussianNB(),',\n",
       " ' ',\n",
       " '\"naive_bayes\"',\n",
       " ':',\n",
       " ' ',\n",
       " 'GaussianNB',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ' \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),',\n",
       " ' ',\n",
       " '\"logit\"',\n",
       " ':',\n",
       " ' ',\n",
       " 'LogisticRegression',\n",
       " '(',\n",
       " 'solver',\n",
       " '=',\n",
       " '\"lbfgs\"',\n",
       " ',',\n",
       " ' ',\n",
       " 'multi_class',\n",
       " '=',\n",
       " '\"auto\"',\n",
       " ')',\n",
       " ',',\n",
       " ' \"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),',\n",
       " ' ',\n",
       " '\"svm\"',\n",
       " ':',\n",
       " ' ',\n",
       " 'SVC',\n",
       " '(',\n",
       " 'kernel',\n",
       " '=',\n",
       " '\"rbf\"',\n",
       " ',',\n",
       " ' ',\n",
       " 'gamma',\n",
       " '=',\n",
       " '\"auto\"',\n",
       " ')',\n",
       " ',',\n",
       " ' \"decision_tree\": DecisionTreeClassifier(),',\n",
       " ' ',\n",
       " '\"decision_tree\"',\n",
       " ':',\n",
       " ' ',\n",
       " 'DecisionTreeClassifier',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ' \"random_forest\": RandomForestClassifier(n_estimators=100),',\n",
       " ' ',\n",
       " '\"random_forest\"',\n",
       " ':',\n",
       " ' ',\n",
       " 'RandomForestClassifier',\n",
       " '(',\n",
       " 'n_estimators',\n",
       " '=',\n",
       " '100',\n",
       " ')',\n",
       " ',',\n",
       " ' \"mlp\": MLPClassifier()',\n",
       " ' ',\n",
       " '\"mlp\"',\n",
       " ':',\n",
       " ' ',\n",
       " 'MLPClassifier',\n",
       " '(',\n",
       " ')',\n",
       " '}',\n",
       " '}',\n",
       " 'The models  dictionary on Lines 23-31 defines the suite of models we will be spot-checking (we’ll review the results of each of these algorithms later in the post):',\n",
       " 'models',\n",
       " 'models',\n",
       " 'models',\n",
       " 'Lines 23-31',\n",
       " 'k-Nearest Neighbor (k-NN)\\nNaïve Bayes\\nLogistic Regression\\nSupport Vector Machines (SVMs)\\nDecision Trees\\nRandom Forests\\nPerceptrons',\n",
       " 'k-Nearest Neighbor (k-NN)',\n",
       " 'Naïve Bayes',\n",
       " 'Logistic Regression',\n",
       " 'Support Vector Machines (SVMs)',\n",
       " 'Decision Trees',\n",
       " 'Random Forests',\n",
       " 'Perceptrons',\n",
       " 'The keys can be entered directly in the terminal following the --model  switch. Here’s an example:',\n",
       " '--model',\n",
       " '--model',\n",
       " '--',\n",
       " 'model',\n",
       " 'Machine Learning in Python\\nShell\\n1\\n$ python classify_irs.py --model knn',\n",
       " 'Machine Learning in Python\\nShell',\n",
       " 'Machine Learning in Python',\n",
       " 'Shell',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Shell',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1\\n$ python classify_irs.py --model knn',\n",
       " '1\\n$ python classify_irs.py --model knn',\n",
       " '1\\n$ python classify_irs.py --model knn',\n",
       " '1\\n$ python classify_irs.py --model knn',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '$ python classify_irs.py --model knn',\n",
       " '$ python classify_irs.py --model knn',\n",
       " '$ python classify_irs.py --model knn',\n",
       " '$',\n",
       " ' ',\n",
       " 'python ',\n",
       " 'classify_irs',\n",
       " '.py',\n",
       " ' ',\n",
       " '--',\n",
       " 'model ',\n",
       " 'knn',\n",
       " 'From there the KNeighborClassifier  will be loaded automatically. This conveniently allows us to call any one of 7 machine learning models one-at-a-time and on demand in a single Python script (no editing the code required)!',\n",
       " 'KNeighborClassifier',\n",
       " 'KNeighborClassifier',\n",
       " 'KNeighborClassifier',\n",
       " 'Moving on, let’s load and split our data:',\n",
       " 'Machine Learning in Python\\nPython\\n33\\n34\\n35\\n36\\n37\\n38\\n# load the Iris dataset and perform a training and testing split,\\n# using 75% of the data for training and 25% for evaluation\\nprint(\"[INFO] loading data...\")\\ndataset = load_iris()\\n(trainX, testX, trainY, testY) = train_test_split(dataset.data,\\n dataset.target, random_state=3, test_size=0.25)',\n",
       " 'Machine Learning in Python\\nPython',\n",
       " 'Machine Learning in Python',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '33\\n34\\n35\\n36\\n37\\n38\\n# load the Iris dataset and perform a training and testing split,\\n# using 75% of the data for training and 25% for evaluation\\nprint(\"[INFO] loading data...\")\\ndataset = load_iris()\\n(trainX, testX, trainY, testY) = train_test_split(dataset.data,\\n dataset.target, random_state=3, test_size=0.25)',\n",
       " '33\\n34\\n35\\n36\\n37\\n38\\n# load the Iris dataset and perform a training and testing split,\\n# using 75% of the data for training and 25% for evaluation\\nprint(\"[INFO] loading data...\")\\ndataset = load_iris()\\n(trainX, testX, trainY, testY) = train_test_split(dataset.data,\\n dataset.target, random_state=3, test_size=0.25)',\n",
       " '33\\n34\\n35\\n36\\n37\\n38\\n# load the Iris dataset and perform a training and testing split,\\n# using 75% of the data for training and 25% for evaluation\\nprint(\"[INFO] loading data...\")\\ndataset = load_iris()\\n(trainX, testX, trainY, testY) = train_test_split(dataset.data,\\n dataset.target, random_state=3, test_size=0.25)',\n",
       " '33\\n34\\n35\\n36\\n37\\n38\\n# load the Iris dataset and perform a training and testing split,\\n# using 75% of the data for training and 25% for evaluation\\nprint(\"[INFO] loading data...\")\\ndataset = load_iris()\\n(trainX, testX, trainY, testY) = train_test_split(dataset.data,\\n dataset.target, random_state=3, test_size=0.25)',\n",
       " '33\\n34\\n35\\n36\\n37\\n38',\n",
       " '33\\n34\\n35\\n36\\n37\\n38',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '# load the Iris dataset and perform a training and testing split,\\n# using 75% of the data for training and 25% for evaluation\\nprint(\"[INFO] loading data...\")\\ndataset = load_iris()\\n(trainX, testX, trainY, testY) = train_test_split(dataset.data,\\n dataset.target, random_state=3, test_size=0.25)',\n",
       " '# load the Iris dataset and perform a training and testing split,\\n# using 75% of the data for training and 25% for evaluation\\nprint(\"[INFO] loading data...\")\\ndataset = load_iris()\\n(trainX, testX, trainY, testY) = train_test_split(dataset.data,\\n dataset.target, random_state=3, test_size=0.25)',\n",
       " '# load the Iris dataset and perform a training and testing split,',\n",
       " '# load the Iris dataset and perform a training and testing split,',\n",
       " '# using 75% of the data for training and 25% for evaluation',\n",
       " '# using 75% of the data for training and 25% for evaluation',\n",
       " 'print(\"[INFO] loading data...\")',\n",
       " 'print',\n",
       " '(',\n",
       " '\"[INFO] loading data...\"',\n",
       " ')',\n",
       " 'dataset = load_iris()',\n",
       " 'dataset',\n",
       " ' ',\n",
       " '=',\n",
       " ' ',\n",
       " 'load_iris',\n",
       " '(',\n",
       " ')',\n",
       " '(trainX, testX, trainY, testY) = train_test_split(dataset.data,',\n",
       " '(',\n",
       " 'trainX',\n",
       " ',',\n",
       " ' ',\n",
       " 'testX',\n",
       " ',',\n",
       " ' ',\n",
       " 'trainY',\n",
       " ',',\n",
       " ' ',\n",
       " 'testY',\n",
       " ')',\n",
       " ' ',\n",
       " '=',\n",
       " ' ',\n",
       " 'train_test_split',\n",
       " '(',\n",
       " 'dataset',\n",
       " '.',\n",
       " 'data',\n",
       " ',',\n",
       " ' dataset.target, random_state=3, test_size=0.25)',\n",
       " ' ',\n",
       " 'dataset',\n",
       " '.',\n",
       " 'target',\n",
       " ',',\n",
       " ' ',\n",
       " 'random_state',\n",
       " '=',\n",
       " '3',\n",
       " ',',\n",
       " ' ',\n",
       " 'test_size',\n",
       " '=',\n",
       " '0.25',\n",
       " ')',\n",
       " 'Our dataset is easily loaded with the dedicated load_iris  method on Line 36. Once the data is in memory, we go ahead and call train_test_split  to separate the data into 75% for training and 25% for testing (Lines 37 and 38).',\n",
       " 'load_iris',\n",
       " 'load_iris',\n",
       " 'load_iris',\n",
       " 'Line 36',\n",
       " 'train_test_split',\n",
       " 'train_test_split',\n",
       " 'train_test_split',\n",
       " 'Lines 37 and 38',\n",
       " 'The final step is to train and evaluate our model:',\n",
       " 'Machine Learning in Python\\nPython\\n40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n# train the model\\nprint(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))\\nmodel = models[args[\"model\"]]\\nmodel.fit(trainX, trainY)\\n # make predictions on our data and show a classification report\\nprint(\"[INFO] evaluating...\")\\npredictions = model.predict(testX)\\nprint(classification_report(testY, predictions,\\n target_names=dataset.target_names))',\n",
       " 'Machine Learning in Python\\nPython',\n",
       " 'Machine Learning in Python',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n# train the model\\nprint(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))\\nmodel = models[args[\"model\"]]\\nmodel.fit(trainX, trainY)\\n # make predictions on our data and show a classification report\\nprint(\"[INFO] evaluating...\")\\npredictions = model.predict(testX)\\nprint(classification_report(testY, predictions,\\n target_names=dataset.target_names))',\n",
       " '40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n# train the model\\nprint(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))\\nmodel = models[args[\"model\"]]\\nmodel.fit(trainX, trainY)\\n # make predictions on our data and show a classification report\\nprint(\"[INFO] evaluating...\")\\npredictions = model.predict(testX)\\nprint(classification_report(testY, predictions,\\n target_names=dataset.target_names))',\n",
       " '40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n# train the model\\nprint(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))\\nmodel = models[args[\"model\"]]\\nmodel.fit(trainX, trainY)\\n # make predictions on our data and show a classification report\\nprint(\"[INFO] evaluating...\")\\npredictions = model.predict(testX)\\nprint(classification_report(testY, predictions,\\n target_names=dataset.target_names))',\n",
       " '40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n# train the model\\nprint(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))\\nmodel = models[args[\"model\"]]\\nmodel.fit(trainX, trainY)\\n # make predictions on our data and show a classification report\\nprint(\"[INFO] evaluating...\")\\npredictions = model.predict(testX)\\nprint(classification_report(testY, predictions,\\n target_names=dataset.target_names))',\n",
       " '40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49',\n",
       " '40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '# train the model\\nprint(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))\\nmodel = models[args[\"model\"]]\\nmodel.fit(trainX, trainY)\\n # make predictions on our data and show a classification report\\nprint(\"[INFO] evaluating...\")\\npredictions = model.predict(testX)\\nprint(classification_report(testY, predictions,\\n target_names=dataset.target_names))',\n",
       " '# train the model\\nprint(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))\\nmodel = models[args[\"model\"]]\\nmodel.fit(trainX, trainY)\\n # make predictions on our data and show a classification report\\nprint(\"[INFO] evaluating...\")\\npredictions = model.predict(testX)\\nprint(classification_report(testY, predictions,\\n target_names=dataset.target_names))',\n",
       " '# train the model',\n",
       " '# train the model',\n",
       " 'print(\"[INFO] using \\'{}\\' model\".format(args[\"model\"]))',\n",
       " 'print',\n",
       " '(',\n",
       " '\"[INFO] using \\'{}\\' model\"',\n",
       " '.',\n",
       " 'format',\n",
       " '(',\n",
       " 'args',\n",
       " '[',\n",
       " '\"model\"',\n",
       " ']',\n",
       " ')',\n",
       " ')',\n",
       " 'model = models[args[\"model\"]]',\n",
       " 'model',\n",
       " ' ',\n",
       " '=',\n",
       " ' ',\n",
       " 'models',\n",
       " '[',\n",
       " 'args',\n",
       " '[',\n",
       " '\"model\"',\n",
       " ']',\n",
       " ']',\n",
       " 'model.fit(trainX, trainY)',\n",
       " 'model',\n",
       " '.',\n",
       " 'fit',\n",
       " '(',\n",
       " 'trainX',\n",
       " ',',\n",
       " ' ',\n",
       " 'trainY',\n",
       " ')',\n",
       " ' ',\n",
       " '# make predictions on our data and show a classification report',\n",
       " '# make predictions on our data and show a classification report',\n",
       " 'print(\"[INFO] evaluating...\")',\n",
       " 'print',\n",
       " '(',\n",
       " '\"[INFO] evaluating...\"',\n",
       " ')',\n",
       " 'predictions = model.predict(testX)',\n",
       " 'predictions',\n",
       " ' ',\n",
       " '=',\n",
       " ' ',\n",
       " 'model',\n",
       " '.',\n",
       " 'predict',\n",
       " '(',\n",
       " 'testX',\n",
       " ')',\n",
       " 'print(classification_report(testY, predictions,',\n",
       " 'print',\n",
       " '(',\n",
       " 'classification_report',\n",
       " '(',\n",
       " 'testY',\n",
       " ',',\n",
       " ' ',\n",
       " 'predictions',\n",
       " ',',\n",
       " ' target_names=dataset.target_names))',\n",
       " ' ',\n",
       " 'target_names',\n",
       " '=',\n",
       " 'dataset',\n",
       " '.',\n",
       " 'target_names',\n",
       " ')',\n",
       " ')',\n",
       " 'Lines 42 and 43 train the Python machine learning model  (also known as “fitting a model”, hence the call to .fit ).',\n",
       " 'Lines 42 and 43',\n",
       " 'model',\n",
       " 'model',\n",
       " 'model',\n",
       " '.fit',\n",
       " '.fit',\n",
       " '.',\n",
       " 'fit',\n",
       " 'From there, we evaluate the model  on the testing set (Line 47) and then print  a classification_report  to our terminal (Lines 48 and 49).',\n",
       " 'model',\n",
       " 'model',\n",
       " 'model',\n",
       " 'Line 47',\n",
       " 'print',\n",
       " 'print',\n",
       " 'print',\n",
       " 'classification_report',\n",
       " 'classification_report',\n",
       " 'classification_report',\n",
       " 'Lines 48 and 49',\n",
       " 'Implementing Python machine learning for images',\n",
       " 'Figure 5: A linear classifier example for implementing Python machine learning for image classification (Inspired by Karpathy’s example in the CS231n course).',\n",
       " '',\n",
       " 'Figure 5: A linear classifier example for implementing Python machine learning for image classification (Inspired by Karpathy’s example in the CS231n course).',\n",
       " 'Figure 5:',\n",
       " 'The following script, classify_images.py , is used to train the same suite of machine learning algorithms above, only on the 3-scenes image dataset.',\n",
       " 'classify_images.py',\n",
       " 'classify_images.py',\n",
       " 'classify_images',\n",
       " '.py',\n",
       " 'It is very similar to our previous Iris dataset classification script, so be sure to compare the two as you follow along.',\n",
       " 'Let’s implement this script now:',\n",
       " 'Machine Learning in Python\\nPython\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom PIL import Image\\nfrom imutils import paths\\nimport numpy as np\\nimport argparse\\nimport os',\n",
       " 'Machine Learning in Python\\nPython',\n",
       " 'Machine Learning in Python',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom PIL import Image\\nfrom imutils import paths\\nimport numpy as np\\nimport argparse\\nimport os',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom PIL import Image\\nfrom imutils import paths\\nimport numpy as np\\nimport argparse\\nimport os',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom PIL import Image\\nfrom imutils import paths\\nimport numpy as np\\nimport argparse\\nimport os',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom PIL import Image\\nfrom imutils import paths\\nimport numpy as np\\nimport argparse\\nimport os',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16',\n",
       " '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom PIL import Image\\nfrom imutils import paths\\nimport numpy as np\\nimport argparse\\nimport os',\n",
       " '# import the necessary packages\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom PIL import Image\\nfrom imutils import paths\\nimport numpy as np\\nimport argparse\\nimport os',\n",
       " '# import the necessary packages',\n",
       " '# import the necessary packages',\n",
       " 'from sklearn.neighbors import KNeighborsClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'neighbors ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'KNeighborsClassifier',\n",
       " 'from sklearn.naive_bayes import GaussianNB',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'naive_bayes ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'GaussianNB',\n",
       " 'from sklearn.linear_model import LogisticRegression',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'linear_model ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'LogisticRegression',\n",
       " 'from sklearn.svm import SVC',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'svm ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'SVC',\n",
       " 'from sklearn.tree import DecisionTreeClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'tree ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'DecisionTreeClassifier',\n",
       " 'from sklearn.ensemble import RandomForestClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'ensemble ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'RandomForestClassifier',\n",
       " 'from sklearn.neural_network import MLPClassifier',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'neural_network ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'MLPClassifier',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'preprocessing ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'LabelEncoder',\n",
       " 'from sklearn.model_selection import train_test_split',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'model_selection ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'train_test_split',\n",
       " 'from sklearn.metrics import classification_report',\n",
       " 'from',\n",
       " ' ',\n",
       " 'sklearn',\n",
       " '.',\n",
       " 'metrics ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'classification_report',\n",
       " 'from PIL import Image',\n",
       " 'from',\n",
       " ' ',\n",
       " 'PIL ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'Image',\n",
       " 'from imutils import paths',\n",
       " 'from',\n",
       " ' ',\n",
       " 'imutils ',\n",
       " 'import',\n",
       " ' ',\n",
       " 'paths',\n",
       " 'import numpy as np',\n",
       " 'import',\n",
       " ' ',\n",
       " 'numpy ',\n",
       " 'as',\n",
       " ' ',\n",
       " 'np',\n",
       " 'import argparse',\n",
       " 'import',\n",
       " ' ',\n",
       " 'argparse',\n",
       " 'import os',\n",
       " 'import',\n",
       " ' ',\n",
       " 'os',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
