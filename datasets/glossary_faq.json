{"0": {"Word": "ACID test", "Description": "A test applied to data for atomicity, consistency, isolation, and durability", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "1": {"Word": "Aggregation", "Description": "A process of searching, gathering and presenting data", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "2": {"Word": "Algorithm", "Description": "A mathematical formula placed in software that performs an analysis on a set of data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "3": {"Word": "Anonymization", "Description": "The severing of links between people in a database and their records to prevent the discovery of the source of the records.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "4": {"Word": "Artificial Intelligence", "Description": "Developing intelligence machines and software that are capable of perceiving the environment and take corresponding action when required and even learn from those actions.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "5": {"Word": "Automatic identification and capture (AIDC)", "Description": "Any method of automatically identifying and collecting data on items, and then storing the data in a computer system. For example, a scanner might collect data about a product being shipped via an RFID chip.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "6": {"Word": "Avro", "Description": "Avro is a data serialization system that allows for encoding the schema of Hadoop files. It is adept at parsing data and performing remote procedure calls", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "7": {"Word": "Behavioral analytics", "Description": "Using data about people\u2019s behavior to understand intent and predict future actions.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "8": {"Word": "Big Data Scientist", "Description": "Someone who is able to develop the algorithms to make sense out of big data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "9": {"Word": "Business Intelligence (BI)", "Description": "The general term used for the identification, extraction, and analysis of data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "10": {"Word": "Cascading", "Description": "Cascading provides a higher level of abstraction for Hadoop, allowing developers to create complex jobs quickly, easily, and in several different languages that run in the JVM, including Ruby, Scala, and more. In effect, this has shattered the skills barrier, enabling Twitter to use Hadoop more broadly.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "11": {"Word": "Call Detail Record (CDR) analysis", "Description": "CDRs contain data that a telecommunications company collects about phone calls, such as time and length of call. This data can be used in any number of analytical applications.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "12": {"Word": "Cassandra", "Description": "Cassandra is a distributed and Open Source database. Designed to handle large amounts of distributed data across commodity servers while providing a highly available service. It is a NoSQL solution that was initially developed by Facebook. It is structured in the form of key-value.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "13": {"Word": "Cell phone data", "Description": "Cell phones generate a tremendous amount of data, and much of it is available for use with analytical applications.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "14": {"Word": "Clickstream Analytics", "Description": "The analysis of users\u2019 Web activity through the items they click on a page.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "15": {"Word": "Classification analysis", "Description": "A systematic process for obtaining important and relevant information about data, also meta data called; data about data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "16": {"Word": "Cloud computing", "Description": "A distributed computing system over a network used for storing data off-premises", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "17": {"Word": "Clustering analysis", "Description": "The process of identifying objects that are similar to each other and cluster them in order to understand the differences as well as the similarities within the data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "18": {"Word": "Cold data storage", "Description": "Storing old data that is hardly used on low-power servers. Retrieving the data will take longer", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "19": {"Word": "Comparative analysis", "Description": "It ensures a step-by-step procedure of comparisons and calculations to detect patterns within very large data sets.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "20": {"Word": "Chukwa", "Description": "Chukwa is a Hadoop subproject devoted to large-scale log collection and analysis. Chukwa is built on top of the Hadoop distributed filesystem (HDFS) and MapReduce framework and inherits Hadoop\u2019s scalability and robustness.  Chukwa also includes a flexible and powerful toolkit for displaying monitoring and analyzing results, in order to make the best use of this collected data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "21": {"Word": "Clojure", "Description": "Clojure is a dynamic programming language based on LISP that uses the Java Virtual Machine (JVM). It is well suited for parallel data processing.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "22": {"Word": "Cloud", "Description": "A broad term that refers to any Internet-based application or service that is hosted remotely.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "23": {"Word": "Columnar database or column-oriented database", "Description": "A database that stores data by column rather than by row. In a row-based database, a row might contain a name, address, and phone number. In a column-oriented database,  all names are in one column, addresses in another, and so on. A key advantage of a columnar database is faster hard disk access.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "24": {"Word": "Comparators", "Description": "Two ways you may compare your keys is by implementing the interface or by implementing the RawComparator interface. In the former approach, you will compare (deserialized) objects, but in the latter approach, you will compare the keys using their corresponding raw bytes.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "25": {"Word": "Complex event processing (CEP)", "Description": "CEP is the process of monitoring and analyzing all events across an organization\u2019s systems and acting on them when necessary in real time.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "26": {"Word": "Confabulation", "Description": "The act of making an intuition-based decision appear to be data-based.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "27": {"Word": "Cross-channel analytics", "Description": "Analysis that can attribute sales, show average order value, or the lifetime value.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "28": {"Word": "Data access", "Description": "The act or method of viewing or retrieving stored data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "29": {"Word": "Dashboard", "Description": "A graphical representation of the analyses performed by the algorithms", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "30": {"Word": "Data aggregation", "Description": "The act of collecting data from multiple sources for the purpose of reporting or analysis.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "31": {"Word": "Data architecture and design", "Description": "How enterprise data is structured. The actual structure or design varies depending on the eventual end result required. Data architecture has three stages or processes: conceptual representation of business entities. the logical representation of the relationships among those entities, and the physical construction of the system to support the functionality.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "32": {"Word": "Database", "Description": "A digital collection of data and the structure around which the data is organized. The data is typically entered into and accessed via a database management system (DBMS).", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "33": {"Word": "Database administrator (DBA)", "Description": "A person, often certified, who is responsible for supporting and maintaining the integrity of the structure and content of a database.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "34": {"Word": "Database as a service (DaaS)", "Description": "A database hosted in the cloud and sold on a metered basis. Examples include Heroku Postgres and Amazon Relational Database Service.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "35": {"Word": "Database management system (DBMS)", "Description": "Software that collects and provides access to data in a structured format.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "36": {"Word": "Data center", "Description": "A physical facility that houses a large number of servers and data storage devices. Data centers might belong to a single organization or sell their services to many organizations.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "37": {"Word": "Data cleansing", "Description": "The act of reviewing and revising data to remove duplicate entries, correct misspellings, add missing data, and provide more consistency.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "38": {"Word": "Data collection", "Description": "Any process that captures any type of data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "39": {"Word": "Data custodian", "Description": "A person responsible for the database structure and the technical environment, including the storage of data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "40": {"Word": "Data-directed decision making", "Description": "Using data to support making crucial decisions.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "41": {"Word": "Data exhaust", "Description": "The data that a person creates as a byproduct of a common activity\u2013for example, a cell call log or web search history.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "42": {"Word": "Data feed", "Description": "A means for a person to receive a stream of data. Examples of data feed mechanisms include RSS or Twitter.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "43": {"Word": "Data governance", "Description": "A set of processes or rules that ensure the integrity of the data and that data management best practices are met.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "44": {"Word": "Data integration", "Description": "The process of combining data from different sources and presenting it in a single view.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "45": {"Word": "Data integrity", "Description": "The measure of trust an organization has in the accuracy, completeness, timeliness, and validity of the data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "46": {"Word": "Data mart", "Description": "The access layer of a data warehouse used to provide data to users.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "47": {"Word": "Data migration", "Description": "The process of moving data between different storage types or formats, or between different computer systems.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "48": {"Word": "Data mining", "Description": "The process of deriving patterns or knowledge from large data sets.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "49": {"Word": "Data model, data modeling", "Description": "A data model defines the structure of the data for the purpose of communicating between functional and technical people to show data needed for business processes, or for communicating a plan to develop how data is stored and accessed among application development team members.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "50": {"Word": "Data point", "Description": "An individual item on a graph or a chart.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "51": {"Word": "Data profiling", "Description": "The process of collecting statistics and information about data in an existing source.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "52": {"Word": "Data quality", "Description": "The measure of data to determine its worthiness for decision making, planning, or operations.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "53": {"Word": "Data replication", "Description": "The process of sharing information to ensure consistency between redundant sources.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "54": {"Word": "Data repository", "Description": "The location of permanently stored data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "55": {"Word": "Data science", "Description": "A recent term that has multiple definitions, but generally accepted as a discipline that incorporates statistics, data visualization, computer programming, data mining, machine learning, and database engineering to solve complex problems.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "56": {"Word": "Data scientist", "Description": "A practitioner of data science.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "57": {"Word": "Data security", "Description": "The practice of protecting data from destruction or unauthorized access.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "58": {"Word": "Data set", "Description": "A collection of data, typically in tabular form.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "59": {"Word": "Data source", "Description": "Any provider of data\u2013for example, a database or a data stream.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "60": {"Word": "Data steward", "Description": "A person responsible for data stored in a data field.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "61": {"Word": "Data structure", "Description": "A specific way of storing and organizing data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "62": {"Word": "Data visualization", "Description": "A visual abstraction of data designed for the purpose of deriving meaning or communicating information more effectively.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "63": {"Word": "Data warehouse", "Description": "A place to store data for the purpose of reporting and analysis.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "64": {"Word": "De-identification", "Description": "The act of removing all data that links a person to a particular piece of information.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "65": {"Word": "Demographic data", "Description": "Data relating to the characteristics of a human population.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "66": {"Word": "Deep Thunder", "Description": "IBM\u2019s weather prediction service that provides weather data to organizations such as utilities, which use the data to optimize energy distribution.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "67": {"Word": "Distributed cache", "Description": "A data cache that is spread across multiple systems but works as one. It is used to improve performance.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "68": {"Word": "Distributed object", "Description": "A software module designed to work with other distributed objects stored on other computers.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "69": {"Word": "Distributed processing", "Description": "The execution of a process across multiple computers connected by a computer network.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "70": {"Word": "Distributed File System", "Description": "Systems that offer simplified, highly available access to storing, analysing and processing data", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "71": {"Word": "Document Store Databases", "Description": "A document-oriented database that is especially designed to store, manage and retrieve documents, also known as semi structured data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "72": {"Word": "Document management", "Description": "The practice of tracking and storing electronic documents and scanned images of paper documents.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "73": {"Word": "Drill", "Description": "An open source distributed system for performing interactive analysis on large-scale datasets. It is similar to Google\u2019s Dremel, and is managed by Apache.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "74": {"Word": "Elasticsearch", "Description": "An open source search engine built on Apache Lucene.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "75": {"Word": "Event analytics", "Description": "Shows the series of steps that led to an action.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "76": {"Word": "Exabyte", "Description": "One million terabytes, or 1 billion gigabytes of information.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "77": {"Word": "External data", "Description": "Data that exists outside of a system.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "78": {"Word": "Extract, transform, and load (ETL)", "Description": "A process used in data warehousing to prepare data for use in reporting or analytics.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "79": {"Word": "Exploratory analysis", "Description": "Finding patterns within data without standard procedures or methods. It is a means of discovering the data and to find the data sets main characteristics.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "80": {"Word": "Failover", "Description": "The automatic switching to another computer or node should one fail.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "81": {"Word": "Flume", "Description": "Flume is a framework for populating Hadoop with data. Agents are populated throughout ones IT infrastructure \u2013 inside web servers, application servers and mobile devices, for example \u2013 to collect data and integrate it into Hadoop.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "82": {"Word": "Grid computing", "Description": "The performing of computing functions using resources from multiple distributed systems. Grid computing typically involves large files and are most often used for multiple applications. The systems that comprise a grid computing network do not have to be similar in design or in the same geographic location.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "83": {"Word": "Graph Databases", "Description": "They use graph structures (a finite set of ordered pairs or certain entities), with edges, properties and nodes for data storage. It provides index-free adjacency, meaning that every element is directly linked to its neighbour element.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "84": {"Word": "Hadoop", "Description": "An open source software library project administered by the Apache Software Foundation. Apache defines Hadoop as \u201ca framework that allows for the distributed processing of large data sets across clusters of computers using a simple programming model.\u201d", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "85": {"Word": "Hama", "Description": "Hama is a distributed computing framework based on Bulk Synchronous Parallel computing techniques for massive scientific computations e.g., matrix, graph and network algorithms. It\u2019s a Top Level Project under the Apache Software Foundation.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "86": {"Word": "HANA", "Description": "A software/hardware in-memory computing platform from SAP designed for high-volume transactions and real-time analytics.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "87": {"Word": "HBase", "Description": "HBase is a non-relational database that allows for low-latency, quick lookups in Hadoop. It adds transactional capabilities to Hadoop, allowing users to conduct updates, inserts and deletes. EBay and Facebook use HBase heavily", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "88": {"Word": "HCatalog", "Description": "HCatalog is a centralized metadata management and sharing service for Apache Hadoop. It allows for a unified view of all data in Hadoop clusters and allows diverse tools, including Pig and Hive, to process any data elements without needing to know physically where in the cluster the data is stored.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "89": {"Word": "HDFS (Hadoop Distributed File System)", "Description": "HDFS (Hadoop Distributed File System) the storage layer of Hadoop, is a distributed, scalable, Java-based file system adept at storing large volumes of unstructured.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "90": {"Word": "Hive", "Description": "Hive is a Hadoop-based data warehousing-like framework originally developed by Facebook. It allows users to write queries in a SQL-like language called HiveQL, which are then converted to MapReduce. This allows SQL programmers with no MapReduce experience to use the warehouse and makes it easier to integrate with business intelligence and visualization tools such as Microstrategy, Tableau, Revolutions Analytics, etc.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "91": {"Word": "Hue", "Description": "Hue (Hadoop User Experience) is an open source web-based interface for making it easier to use Apache Hadoop. It features a file browser for HDFS, an Oozie Application for creating workflows and coordinators, a job designer/browser for MapReduce, a Hive and Impala UI, a Shell, a collection of Hadoop API and more.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "92": {"Word": "Impala", "Description": "Impala (By Cloudera) provides fast, interactive SQL queries directly on your Apache Hadoop data stored in HDFS or HBase using the same metadata, SQL syntax (Hive SQL), ODBC driver and user interface (Hue Beeswax) as Apache Hive. This provides a familiar and unified platform for batch-oriented or real-time queries.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "93": {"Word": "In-database analytics", "Description": "The integration of data analytics into the data warehouse.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "94": {"Word": "In-memory database", "Description": "Any database system that relies on memory for data storage.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "95": {"Word": "In-memory data grid (IMDG)", "Description": "The storage of data in memory across multiple servers for the purpose of greater scalability and faster access or analytics.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "96": {"Word": "Internet of Things", "Description": "Ordinary devices that are connected to the internet at any time any where via sensors", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "97": {"Word": "Kafka", "Description": "Kafka (developed by LinkedIn) is a distributed publish-subscribe messaging system that offers a solution capable of handling all data flow activity and processing these data on a consumer website. This type of data (page views, searches, and other user actions) are a key ingredient in the current social web.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "98": {"Word": "Key Value Stores", "Description": "Key value stores allow the application to store its data in a schema-less way. The data could be stored in a datatype of a programming language or an object. Because of this, there is no need for a fixed data model.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "99": {"Word": "KeyValue Databases", "Description": "They store data with a primary key, a uniquely identifiable record, which makes easy and fast to look up. The data stored in a KeyValue is normally some kind of primitive of the programming language.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "100": {"Word": "Latency", "Description": "Any delay in a response or delivery of data from one point to another.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "101": {"Word": "Linked data", "Description": "As described by World Wide Web inventor Time Berners-Lee, \u201cCherry-picking common attributes or languages to identify connections or relationships between disparate sources of data.\u201d", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "102": {"Word": "Load balancing", "Description": "The process of distributing workload across a computer network or computer cluster to optimize performance.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "103": {"Word": "Location analytics", "Description": "Location analytics brings mapping and map-driven analytics to enterprise business systems and data warehouses. It allows you to associate geospatial information with datasets.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "104": {"Word": "Location data", "Description": "Data that describes a geographic location.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "105": {"Word": "Log file", "Description": "A file that a computer, network, or application creates automatically to record events that occur during operation\u2013for example, the time a file is accessed.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "106": {"Word": "Machine-generated data", "Description": "Any data that is automatically created from a computer process, application, or other non-human source.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "107": {"Word": "Machine2Machine data", "Description": "Two or more machines that are communicating with each other", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "108": {"Word": "Machine learning", "Description": "The use of algorithms to allow a computer to analyze data for the purpose of \u201clearning\u201d what action to take when a specific pattern or event occurs.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "109": {"Word": "MapReduce", "Description": "MapReduce is a software framework that serves as the compute layer of Hadoop. MapReduce jobs are divided into two (obviously named) parts. The \u201cMap\u201d function divides a query into multiple parts and processes data at the node level. The \u201cReduce\u201d function aggregates the results of the \u201cMap\u201d function to determine the \u201canswer\u201d to the query.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "110": {"Word": "Mashup", "Description": "The process of combining different datasets within a single application to enhance output\u2013for example, combining demographic data with real estate listings.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "111": {"Word": "Mahout", "Description": "Mahout is a data mining library. It takes the most popular data mining algorithms for performing clustering, regression testing and statistical modeling and implements them using the Map Reduce model.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "112": {"Word": "Metadata", "Description": "Data about data; gives information about what the data is about.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "113": {"Word": "MongoDB", "Description": "MongoDB is a NoSQL database oriented to documents, developed under the open source concept. It saves data structures in JSON documents with a dynamic scheme (called MongoDB BSON format), making the integration of the data in certain applications more easily and quickly.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "114": {"Word": "MPP database", "Description": "A database optimized to work in a massively parallel processing environment.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "115": {"Word": "Multi-Dimensional Databases", "Description": "A database optimized for data online analytical processing (OLAP) applications and for data warehousing.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "116": {"Word": "MultiValue Databases", "Description": "They are a type of NoSQL and multidimensional databases that understand 3 dimensional data directly. They are primarily giant strings that are perfect for manipulating HTML and XML strings directly", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "117": {"Word": "Network analysis", "Description": "Viewing relationships among the nodes in terms of the network or graph theory, meaning analysing connections between nodes in a network and the strength of the ties.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "118": {"Word": "NewSQL", "Description": "An elegant, well-defined database system that is easier to learn and better than SQL. It is even newer than NoSQL", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "119": {"Word": "NoSQL", "Description": "NoSQL (commonly interpreted as \u201cnot only SQL\u201c) is a broad class of database management systems identified by non-adherence to the widely used relational database management system model. NoSQL databases are not built primarily on tables, and generally do not use SQL for data manipulation.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "120": {"Word": "Object Databases", "Description": "They store data in the form of objects, as used by object-oriented programming. They are different from relational or graph databases and most of them offer a query language that allows object to be found with a declarative programming approach.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "121": {"Word": "Object-based Image Analysis", "Description": "Analysing digital images can be performed with data from individual pixels, whereas object-based image analysis uses data from a selection of related pixels, called objects or image objects.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "122": {"Word": "Online analytical processing (OLAP)", "Description": "The process of analyzing multidimensional data using three operations: consolidation (the aggregation of available), drill-down (the ability for users to see the underlying details), and slice and dice (the ability for users to select subsets and view them from different perspectives).", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "123": {"Word": "Online transactional processing (OLTP)", "Description": "The process of providing users with access to large amounts of transactional data in a way that they can derive meaning from it.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "124": {"Word": "OpenDremel", "Description": "The open source version of Google\u2019s Big Query java code. It is being integrated with Apache Drill.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "125": {"Word": "Open Data Center Alliance (ODCA)", "Description": "A consortium of global IT organizations whose goal is to speed the migration of cloud computing.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "126": {"Word": "Operational data store (ODS)", "Description": "A location to gather and store data from multiple sources so that more operations can be performed on it before sending to the data warehouse for reporting.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "127": {"Word": "Oozie", "Description": "Oozie is a workflow processing system that lets users define a series of jobs written in multiple languages \u2013 such as Map Reduce, Pig and Hive \u2014 then intelligently link them to one another. Oozie allows users to specify, for example, that a particular query is only to be initiated after specified previous jobs on which it relies for data are completed.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "128": {"Word": "Parallel data analysis", "Description": "Breaking up an analytical problem into smaller components and running algorithms on each of those components at the same time. Parallel data analysis can occur within the same system or across multiple systems.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "129": {"Word": "Parallel method invocation (PMI)", "Description": "Allows programming code to call multiple functions in parallel.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "130": {"Word": "Parallel processing", "Description": "The ability to execute multiple tasks at the same time.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "131": {"Word": "Parallel query", "Description": "A query that is executed over multiple system threads for faster performance.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "132": {"Word": "Pattern recognition", "Description": "The classification or labeling of an identified pattern in the machine learning process.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "133": {"Word": "Pentaho", "Description": "Pentaho offers a suite of open source Business Intelligence (BI) products called Pentaho Business Analytics providing data integration, OLAP services, reporting, dashboarding, data mining and ETL capabilities", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "134": {"Word": "Petabyte", "Description": "One million gigabytes or 1,024 terabytes.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "135": {"Word": "Pig", "Description": "Pig Latin is a Hadoop-based language developed by Yahoo. It is relatively easy to learn and is adept at very deep, very long data pipelines (a limitation of SQL).", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "136": {"Word": "Predictive analytics", "Description": "Using statistical functions on one or more datasets to predict trends or future events.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "137": {"Word": "Predictive modeling", "Description": "The process of developing a model that will most likely predict a trend or outcome.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "138": {"Word": "Public data", "Description": "Public information or data sets that were created with public funding", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "139": {"Word": "Query", "Description": "Asking for information to answer a certain question", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "140": {"Word": "Query analysis", "Description": "The process of analyzing a search query for the purpose of optimizing it for the best possible result.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "141": {"Word": "R", "Description": "R is a language and environment for statistical computing and graphics. It is a GNU project which is similar to the S language. R provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, \u2026) and graphical techniques, and is highly extensible.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "142": {"Word": "Re-identification", "Description": "Combining several data sets to find a certain person within anonymized data", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "143": {"Word": "Real-time data", "Description": "Data that is created, processed, stored, analysed and visualized within milliseconds", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "144": {"Word": "Recommendation engine", "Description": "An algorithm that analyzes a customer\u2019s purchases and actions on an e-commerce site and then uses that data to recommend complementary products.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "145": {"Word": "Reference data", "Description": "Data that describes an object and its properties. The object may be physical or virtual.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "146": {"Word": "Risk analysis", "Description": "The application of statistical methods on one or more datasets to determine the likely risk of a project, action, or decision.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "147": {"Word": "Root-cause analysis", "Description": "The process of determining the main cause of an event or problem.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "148": {"Word": "Routing analysis", "Description": "Finding the optimized routing using many different variables for a certain means of transport in order to decrease fuel costs and increase efficiency.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "149": {"Word": "Scalability", "Description": "The ability of a system or process to maintain acceptable performance levels as workload or scope increases.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "150": {"Word": "Schema", "Description": "The structure that defines the organization of data in a database system.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "151": {"Word": "Search data", "Description": "Aggregated data about search terms used over time.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "152": {"Word": "Semi-structured data", "Description": "Data that is not structured by a formal data model, but provides other means of describing the data and hierarchies.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "153": {"Word": "Sentiment analysis", "Description": "The application of statistical functions on comments people make on the web and through social networks to determine how they feel about a product or company.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "154": {"Word": "Server", "Description": "A physical or virtual computer that serves requests for a software application and delivers those requests over a network.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "155": {"Word": "Spatial analysis", "Description": "It refers to analysing spatial data such geographic data or topological data to identify and understand patterns and regularities within data distributed in geographic space.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "156": {"Word": "SQL", "Description": "A programming language for retrieving data from a relational database", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "157": {"Word": "Sqoop", "Description": "Sqoop is a connectivity tool for moving data from non-Hadoop data stores \u2013 such as relational databases and data warehouses \u2013 into Hadoop. It allows users to specify the target location inside of Hadoop and instruct Sqoop to move data from Oracle, Teradata or other relational databases to the target.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "158": {"Word": "Storm", "Description": "Storm is a system of real-time distributed computing, open source and free, born into Twitter. Storm makes it easy to reliably process unstructured data flows in the field of real-time processing, which made Hadoop for batch processing.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "159": {"Word": "Software as a service (SaaS)", "Description": "Application software that is used over the web by a thin client or web browser. Salesforce is a well-known example of SaaS.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "160": {"Word": "Storage", "Description": "Any means of storing data persistently.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "161": {"Word": "Storm", "Description": "An open-source distributed computation system designed for processing multiple data streams in real time.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "162": {"Word": "Structured data", "Description": "Data that is organized by a predetermined structure.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "163": {"Word": "Structured Query Language (SQL)", "Description": "A programming language designed specifically to manage and retrieve data from a relational database system.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "164": {"Word": "Text analytics", "Description": "The application of statistical, linguistic, and machine learning techniques on text-based sources to derive meaning or insight.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "165": {"Word": "Transactional data", "Description": "Data that changes unpredictably. Examples include accounts payable and receivable data, or data about product shipments.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "166": {"Word": "Thrift", "Description": "\u201cThrift is a software framework for scalable cross-language services development. It combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk, and OCaml.\u201d", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "167": {"Word": "Unstructured data", "Description": "Data that has no identifiable structure\u2013for example, the text of email messages.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "168": {"Word": "Value", "Description": "All that available data will create a lot of value for organizations, societies and consumers. Big data means big business and every industry will reap the benefits from big data.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "169": {"Word": "Volume", "Description": "The amount of data, ranging from megabytes to brontobytes", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "170": {"Word": "Visualization", "Description": "A visual abstraction of data designed for the purpose of deriving meaning or communicating information more effectively.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "171": {"Word": "WebHDFS Apache Hadoop", "Description": "WebHDFS Apache Hadoop provides native libraries for accessing HDFS. However, users prefer to use HDFS remotely over the heavy client side native libraries. For example, some applications need to load data in and out of the cluster, or to externally interact with the HDFS data. WebHDFS addresses these issues by providing a fully functional HTTP REST API to access HDFS.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "172": {"Word": "Weather data", "Description": "Real-time weather data is now widely available for organizations to use in a variety of ways. For example, a logistics company can monitor local weather conditions to optimize the transport of goods. A utility company can adjust energy distribution in real time.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "173": {"Word": "XML Databases", "Description": "XML Databases allow data to be stored in XML format. XML databases are often linked to document-oriented databases. The data stored in an XML database can be queried, exported and serialized into any format needed.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "174": {"Word": "ZooKeeper", "Description": "ZooKeeper is a software project of the Apache Software Foundation, a service that provides centralized configuration and open code name registration for large distributed systems. ZooKeeper is a subproject of Hadoop.", "Url": "https://bigdata-madesimple.com/big-data-a-to-zz-a-glossary-of-big-data-terminology/", "Attachment_Url": []}, "175": {"Word": "Accuracy", "Description": "Accuracy is a metric by which one can examine how good is the machine learning model. Let us look at the confusion matrix to understand it in a better way:\nSo, the accuracy is the ratio of correctly predicted classes to the total classes predicted. Here, the accuracy will be:", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Accuracy1.png", "https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Accuracy2.png"]}, "176": {"Word": "Adam Optimization", "Description": "The Adam Optimization algorithm is used in training deep learning models. It is an extension to Stochastic Gradient Descent. In this optimization algorithm, running averages of both the gradients and the second moments of the gradients are used. It is used to compute adaptive learning rates for each parameter.\nFeatures:\nIt is computationally efficient and has little memory requirements\nIt is invariant to diagonal rescaling of the gradients\nAdam works well in practice as compared to other stochastic optimization methods", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "177": {"Word": "Apache Spark", "Description": "Apache Spark is an open-source cluster computing framework. Spark can be deployed in a variety of ways, provides native bindings for the Java, Scala, Python, and R programming languages, and supports SQL, streaming data, and machine learning. Some of the key features of Apache Spark are listed below:\nSpeed \u2212 Spark helps to run an application in Hadoop cluster, up to 100 times faster in memory, and 10 times faster when running on disk\nSpark supports popular data science programming languages such as R, Python, and Scala\nSpark also has a library called MLlIB which includes basic machine learning including classification, regression, and clustering", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "178": {"Word": "Autoregression", "Description": "Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. The autoregressive model specifies that the output variable depends linearly on its own previous values. In this technique input variables are taken as observations at previous time steps, called lag variables.\nFor example, we can predict the value for the next time step (t+1) given the observations at the last two time steps (t-1 and t-2). As a regression model, this would look as follows:\nX(t+1) = b0 + b1*X(t-1) + b2*X(t-2)\nSince the regression model uses data from the same input variable at previous time steps, it is referred to as an autoregression.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "179": {"Word": "Backpropogation", "Description": "In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation. Back-propagation (BP) algorithms work by determining the loss (or error) at the output and then propagating it back into the network. The weights are updated to minimize the error resulting from each neuron. The first step in minimizing the error is to determine the gradient (Derivatives) of each node w.r.t. the final output.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "180": {"Word": "Bagging", "Description": "Bagging or bootstrap averaging is a technique where multiple models are created on the subset of data, and the final predictions are determined by combining the predictions of all the models. Some of the algorithms that use bagging technique are :\nBagging meta-estimator\nRandom Forest", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Bagging.png"]}, "181": {"Word": "Bar Chart", "Description": "Bar charts are a type of graph that are used to display and compare the numbers, frequency or other measures (e.g. mean) for different discrete categories of data. They are used for categorical variables. Simple example of a bar chart:\nTo gain a better understanding about bar charts, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/bar.png"]}, "182": {"Word": "Bayes Theorem", "Description": "Bayes\u2019 theorem is used to calculate the conditional probability. Conditional probability is the probability of an event \u2018B\u2019 occurring given the related event \u2018A\u2019 has already occurred.\nFor example, Let\u2019s say a clinic wants to cure cancer of the patients visiting the clinic.\nA represents an event \u201cPerson has cancer\u201d\nB represents an event \u201cPerson is a smoker\u201d\nThe clinic wishes to calculate the proportion of smokers from the ones diagnosed with cancer.\nTo do so use the Bayes\u2019 Theorem (also known as Bayes\u2019 rule) which is as follows:\nTo understand Bayes\u2019 Theorem in detail, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["http://www.statisticshowto.com/wp-content/uploads/2014/02/bayes-theorem.jpg"]}, "183": {"Word": "Bayesian Statistics", "Description": "Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data. It differs from classical frequentist approach and is based on the use of Bayesian probabilities to summarize evidence. For more details, read here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "184": {"Word": "Bias-Variance Trade-off", "Description": "The error emerging from any model can be broken down into components mathematically.\nFollowing are these component :\nBias error is useful to quantify how much on an average are the predicted values different from the actual value\nVariance on the other side quantifies how are the prediction made on same observation different from each other\nA high bias error means we have a under-performing model which keeps on missing important trends. A high variance model will over-fit on your training population and perform badly on any observation beyond training. In order to have a perfect fit in the model, the bias and variance should be balanced which is bias variance trade off.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/bias1.png", "https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/bias2.png"]}, "185": {"Word": "Big Data", "Description": "Big data is a term that describes the large volume of data \u2013 both structured and unstructured. But it\u2019s not the amount of data that\u2019s important. It\u2019s how organizations use this large amount of data to generate insights. Companies use various tools, techniques and resources to make sense of this data to derive effective business strategies.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "186": {"Word": "Binary Variable", "Description": "Binary variables are those variables which can have only two unique values. For example, a variable \u201cSmoking Habit\u201d can contain only two values like \u201cYes\u201d and \u201cNo\u201d.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "187": {"Word": "Binomial Distribution", "Description": "Binomial Distribution is applied only on discrete random variables. It is a method of calculating probabilities for experiments having fixed number of trials.\nBinomial distribution has following properties:\nThe experiment should have finite number of trials\nThere should be two outcomes in a trial: success and failure\nTrials are independent\nProbability of success (p) remains constant\nFor a distribution to qualifying as binomial, all of the properties must be satisfied.\nSo, which kind of distributions would be considered binomial? Let\u2019s answer it using few examples:\nSuppose, you need to find the probability of scoring bull\u2019s eye on a dart. Can it be called as binomial distribution? No, because the number of trials isn\u2019t fixed. I could hit the bull\u2019s eye on the 1st attempt or 3rd attempt or I might not be able to hit it at all. Therefore, trials aren\u2019t fixed.\nA football match can have resulted in 3 ways: Win, Lose or Draw. Thus, if we are asked to find the probability of winning in this case, binomial distribution cannot be used because there are more than two outcomes.\nTossing a fair coin 20 times is a case of binomial distribution as here we have finite number of trials 20 with only two outcomes \u201cHead\u201d or \u201cTail\u201d. These trials are independent and probability of success is 1/2 across all trials.\nThe formula to calculate probability using Binomial Distribution is:\nP ( X = r ) = nCr (p\u02c6r)* (1-p) * (n-r)\nwhere:\nn : No. of trials\nr : No. of success\np : the probability of success\n1 \u2013 p : Probability of failure\nnCr : binomial coefficient given by n!/k!(n-k)!", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "188": {"Word": "Boosting", "Description": "Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Some of the boosting algorithms are:\nAdaBoost\nGBM\nXGBM\nLightGBM\nCatBoost\nTo learn more about boosting algorithms, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "189": {"Word": "Bootstrapping", "Description": "Bootstrapping is the process of dividing the dataset into multiple subsets, with replacement. Each subset is of the same size of the dataset. These samples are called bootstrap samples.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "190": {"Word": "Box Plot", "Description": "It displays the full range of variation (from min to max), the likely range of variation (the Interquartile range), and a typical value (the median). Below is a visualization of a box plot:\nSome of the inferences that can be made from a box plot:\nMedian: Middle quartile marks the median.\nMiddle box represents the 50% of the data\nFirst quartile: 25% of data falls below these line\nThird quartile: 75% of data falls below these line.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/box.png"]}, "191": {"Word": "Business Analytics", "Description": "Business analytics is mainly used to show the practical methodology followed by an organization for exploring data to gain insights. The methodology focusses on statistical analysis of the data.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "192": {"Word": "Business Intelligence", "Description": "Business intelligence are a set of strategies, applications, data, technologies used by an organization for data collection, analysis and generating insights to derive strategic business opportunities.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "193": {"Word": " Categorical Variable", "Description": " Categorical variables (or nominal variables) are those variables which have discrete qualitative values. For example, names of cities are categorical like Delhi, Mumbai, Kolkata. Read in detail  here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "194": {"Word": " Classification", "Description": " It is supervised learning method where the output variable is a category, such as \u201cMale\u201d or \u201cFemale\u201d or \u201cYes\u201d and \u201cNo\u201d.\nFor example: Classification Algorithms like Logistic Regression, Decision Tree, K-NN, SVM etc.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "195": {"Word": " Classification Threshold", "Description": "Classification threshold is the value which is used to classify a new observation as 1 or 0. When we get an output as probabilities and have to classify them into classes, we decide some threshold value and if the probability is above that threshold value we classify it as 1, and 0 otherwise. To find the optimal threshold value, one can plot the AUC-ROC and keep changing the threshold value. The value which will give the maximum AUC will be the optimal threshold value.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "196": {"Word": "Clustering", "Description": "Clustering is an unsupervised learning method used to discover the inherent groupings in the data.  For example: Grouping customers on the basis of their purchasing behaviour which is further used to segment the customers. And then the companies can use the appropriate marketing tactics to generate more profits.\nExample of clustering algorithms: K-Means, hierarchical clustering, etc.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "197": {"Word": "Computer Vision", "Description": "Computer Vision is a field of computer science that deals with enabling computers to visualize, process and identify images/videos in the same way that a human vision does. In the recent times, the major driving forces behind Computer Vision has been the emergence of deep learning, rise in computational power and a huge amount of image data. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. Some of the key applications of Computer Vision are:\nPedestrians, cars, road detection in smart (self-driving) cars\nObject recognition\nObject tracking\nMotion analysis\nImage restoration", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "198": {"Word": "Concordant-Discordant Ratio", "Description": "Concordant and discordant pairs are used to describe the relationship between pairs of observations. To calculate the concordant and discordant pairs, the data are treated as ordinal. The number of concordant and discordant pairs are used in calculations for Kendall\u2019s tau, which measures the association between two ordinal variables.\nLet\u2019s say you had two movie reviewers rank a set of 5 movies:\nMovie Reviewer 1 Reviewer 2\nA 1 1\nB 2 2\nC 3 4\nD 4 3\nE 5 6\nThe ranks given by the reviewer 1 are ordered in ascending order, this way we can compare the rankings given by both the reviewers.\nConcordant Pair \u2013 2 entities would form a concordant pair if one of them is ranked higher than the other consistently. For example, in the table above B and D form a concordant pair because B has been ranked higher than D by both the reviewers.\nDiscordant Pair \u2013 C and D are discordant because they have been ranked in opposite order by the reviewers.\nConcordant Pair or Discordant Pair ratio = (No. of concordant or discordant pairs) / (Total pairs tested)", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "199": {"Word": "Confidence Interval", "Description": "A confidence interval is used to estimate what percent of a population fits a category based on the results from a sample population. For example, if 70 adults own a cell phone in a random sample of 100 adults, we can be fairly confident that the true percentage amongst the population is somewhere between 61% and 79%. Read more here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "200": {"Word": "Confusion Matrix", "Description": "A confusion matrix is a table that is often used to describe the performance of a classification model. It is a N * N matrix, where N is the number of classes. We form confusion matrix between prediction of model classes Vs actual classes. The 2nd quadrant is called type II error or False Negatives, whereas 3rd quadrant is called type I error or False positives", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/01/Confusion_matrix.png"]}, "201": {"Word": "Continuous Variable", "Description": "Continuous variables are those variables which can have infinite number of values but only in a specific range. For example, height is a continuous variable. Read more here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "202": {"Word": "Convergence", "Description": "Convergence refers to moving towards union or uniformity. An iterative algorithm is said to converge when as the iterations proceed the output gets closer and closer to a specific value.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "203": {"Word": "Convex Function", "Description": "A real value function is called convex if the line segment between any two points on the graph of the function lies above or on the graph.\nConvex functions play an important role in many areas of mathematics. They are especially important in the study of optimization problems where they are distinguished by a number of convenient properties.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Convex.png"]}, "204": {"Word": "Correlation", "Description": "Correlation is the ratio of covariance of two variables to a product of variance (of the variables). It takes a value between +1 and -1. An extreme value on both the side means they are strongly correlated with each other. A value of zero indicates a NIL correlation but not a non-dependence. You\u2019ll understand this clearly in one of the following answers.\nThe most widely used correlation coefficient is Pearson Coefficient. Here is the mathematical formula to derive Pearson Coefficient.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Co.png"]}, "205": {"Word": "Cosine Similarity", "Description": "Cosine Similarity is the cosine of the angle between 2 non-zero vectors. Two parallel vectors have a cosine similarity of 1 and two vectors at 90\u00b0 have a cosine similarity of 0. Suppose we have two vectors A and B, cosine similarity of these vectors can be calculated by dividing the dot product of A and B with the product of the magnitude of the two vectors.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Cosi.png"]}, "206": {"Word": "Cost Function", "Description": "Cost function is used to define and measure the error of the model. The cost function is given by:\nHere,\nh(x) is the prediction\ny is the actual value\nm is the number of rows in the training set\nLet us understand it with an example:\nSo let\u2019s say, you increase the size of a particular shop, where you predicted that the sales would be higher. But despite increasing the size, the sales in that shop did not increase that much. So the cost applied in increasing the size of the shop, gave you negative results. So, we need to minimize these costs. Therefore we make use of cost function to minimize the loss.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/cost.png"]}, "207": {"Word": "Covariance", "Description": "Covariance is a measure of the joint variability of two random variables. It\u2019s similar to variance, but where variance tells you how a single variable varies, co variance tells you how two variables vary together. The formula for covariance is:\nWhere,\nx = the independent variable\ny = the dependent variable\nn = number of data points in the sample\nx bar = the mean of the independent variable x\ny bar = the mean of the dependent variable y\nA positive covariance means the variables are positively related, while a negative covariance means the variables are inversely related.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Co1.png"]}, "208": {"Word": "Cross Entropy", "Description": "In information theory, the cross entropy between two probability distributions and over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an \u201cunnatural\u201d probability distribution , rather than the \u201ctrue\u201d. Cross entropy can be used to define the loss function in machine learning and optimization.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "209": {"Word": "Cross Validation", "Description": "Cross Validation is a technique which involves reserving a particular sample of a dataset which is not used to train the model. Later, the model is tested on this sample to evaluate the performance. There are various methods of performing cross validation such as:\nLeave one out cross validation (LOOCV)\nk-fold cross validation\nStratified k-fold cross validation\nAdversarial validation", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "210": {"Word": "Data Mining", "Description": "Data mining is a study of extracting useful information from structured/unstructured data taken from various sources. This is done usually for\nMining for frequent patterns\nMining for associations\nMining for correlations\nMining for clusters\nMining for predictive analysis\nData Mining is done for purposes like Market Analysis, determining customer purchase pattern, financial planning, fraud detection, etc", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "211": {"Word": "Data Science", "Description": "Data science is a combination of data analysis, algorithmic development and technology in order to solve analytical problems. The main goal is a use of data to generate business value.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "212": {"Word": "Data Transformation", "Description": "Data transformation is the process to convert data from one form to the other. This is usually done at a preprocessing step.\nFor instance, replacing a variable x by the square root of x\n  X SQUARE_ROOT(X)\n1 1\n4 2\n9 3\n ", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/03/Transformation_1.png"]}, "213": {"Word": "Database", "Description": "Database (abbreviated as DB) is an structured collection of data. The collected information is organised in a way such that it is easily accessible by the computer. Databases are built and managed by using database programming languages. The most common database language is SQL.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "214": {"Word": "Dataframe", "Description": "DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. DataFrame accepts many different kinds of input:\nDict of 1D ndarrays, lists, dicts, or Series\n2-D numpy.ndarray\nStructured or record ndarray\nA series\nAnother DataFrame", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "215": {"Word": "Dataset", "Description": "A dataset (or data set) is a collection of data. A dataset is organized into some type of data structure. In a database, for example, a dataset might contain a collection of business data (names, salaries, contact information, sales figures, and so forth). Several characteristics define a dataset\u2019s structure and properties. These include the number and types of the attributes or variables, and various statistical measures applicable to them, such as standard deviation and kurtosis.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "216": {"Word": "Dashboard", "Description": "Dashboard is an information management tool which is used to visually track, analyze and display key performance indicators, metrics and key data points. Dashboards can be customised to fulfil the requirements of a project. It can be used to connect files, attachments, services and APIs which is displayed in the form of tables, line charts, bar charts and gauges. Popular tools for building dashboards include Excel and Tableau.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "217": {"Word": "DBScan", "Description": "DBSCAN is the acronym for Density-Based Spatial Clustering of Applications with Noise. It is a clustering algorithm that isolates different density regions by forming clusters. For a given set of points, it groups the points which are closely packed.\nThe algorithm has two important features:\ndistance\nthe minimum number of points required to form a dense region\nThe steps involved in this algorithm are:\nBeginning with an arbitrary starting point it extracts the neighborhood of this point using the distance\nIf there are sufficient neighboring points around this point then a cluster is formed\nThis point is then marked as visited\nA new unvisited point is retrieved and processed, leading to the discovery of a further cluster or noise\nThis process continues until all points are marked as visited\nThe below image is an example of DBScan on a set of normalized data points:\n ", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/DBScan.png"]}, "218": {"Word": "Decision Boundary", "Description": "In a statistical-classification problem with two or more classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class. How well the classifier works depends upon how closely the input patterns to be classified resemble the decision boundary. In the example sketched below, the correspondence is very close, and one can anticipate excellent performance.\nHere the lines separating each class are decision boundaries.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/DB.png"]}, "219": {"Word": "Decision Tree", "Description": "Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input & output variables. In this technique, we split the population (or sample) into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\nRead more here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26113031/tvTree.jpg"]}, "220": {"Word": " Deep Learning", "Description": "Deep Learning is associated with a machine learning algorithm (Artificial Neural Network, ANN) which uses the concept of human brain to facilitate the modeling of arbitrary functions. ANN requires a vast amount of data and this algorithm is highly flexible when it comes to model multiple outputs simultaneously. To understand ANN in detail, read here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "221": {"Word": "Descriptive Statistics", "Description": "Descriptive statistics is comprised of those values which explains the spread and central tendency of data. For example, mean is a way to represent central tendency of the data, whereas IQR is a way to represent spread of the data.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "222": {"Word": "Dependent Variable", "Description": "A dependent variable is what you measure and which is affected by independent / input variable(s). It is called dependent because it \u201cdepends\u201d on the independent variable. For example, let\u2019s say we want to predict the smoking habits of people. Then the person smokes \u201cyes\u201d or \u201cno\u201d is the dependent variable.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "223": {"Word": " Decile", "Description": "Decile divides a series into 10 equal parts. For any series, there are 10 decile denoted by D1, D2, D3 \u2026 D10. These are known as First Decile , Second Decile and so on.\nFor example, the diagram below shows the health score of a patient from range 0 to 60. Nine deciles split the patients into 10 groups", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26080337/histoDeciles-300x205.gif"]}, "224": {"Word": "Degree of Freedom", "Description": "It is the number of variables that have the choice of having more than one arbitrary value.\nFor example, in a sample of size 10 with mean 10, 9 values can be arbitrary but the 10th value is forced by the sample mean. So, we can choose any number for 9 values but the 10th value must be such that the mean is 10. So, the degree of freedom in this case will be 9.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "225": {"Word": "Dimensionality Reduction", "Description": "Dimensionality Reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. Dimension Reduction refers to the process of converting a set of data having vast dimensions into data with lesser dimensions ensuring that it conveys similar information concisely. Some of the benefits of dimensionality reduction:\nIt helps in data compressing and reducing the storage space required\nIt fastens the time required for performing same computations\nIt takes care of multicollinearity that improves the model performance. It removes redundant features\nReducing the dimensions of data to 2D or 3D may allow us to plot and visualize it precisely\nIt is helpful in noise removal also and as result of that we can improve the performance of models", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "226": {"Word": "Dplyr", "Description": "Dplyr is a popular data manipulation package in R. It makes data manipulation, cleaning, summarizing very user friendly. Dplyr can work not only with the local datasets, but also with remote database tables, using exactly the same R code.\nIt can be easily installed using the following code from the R console:\ninstall.packages(\"dplyr\")", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "227": {"Word": "Dummy Variable", "Description": "Dummy Variable is another name for Boolean variable. An example of dummy variable is that it takes value 0 or 1. 0 means value is true (i.e. age < 25) and 1 means value is false (i.e. age >= 25)", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "228": {"Word": "Early Stopping", "Description": "Early stopping is a technique for avoiding overfitting when training a machine learning model with iterative method. We set the early stopping in such a way that when the performance has stopped improving on the held-out validation set, the model training stops.\nFor example, in XGBoost, as you train more and more trees, you will overfit your training dataset. Early stopping enables you to specify a validation dataset and the number of iterations after which the algorithm should stop if the score on your validation dataset didn\u2019t increase.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "229": {"Word": "EDA", "Description": "EDA or exploratory data analysis is a phase used for data science pipeline in which the focus is to understand insights of the data through visualization or by statistical analysis.\nThe steps involved in EDA are:\nVariable IdentificationIn this step, we identify the data type and category of variables\nUnivariate analysis\nMultivariate analysis\nRefer here for a comprehensive guide to doing EDA.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Data_exploration_2.png"]}, "230": {"Word": "ETL", "Description": "ETL is the acronym for Extract, Transform and Load. An ETL system has the following properties:\nIt extracts data from the source systems\nIt enforces data quality and consistency standards\nDelivers data in a presentation-ready format\nThis data can be used by application developers to build applications and end users for making decisions.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "231": {"Word": "Evaluation Metrics`", "Description": "The purpose of evaluation metric is to measure the quality of the statistical / machine learning model. For example, below are a few evaluation metrics\nAUC\nROC score\nF-Score\nLog-Loss", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "232": {"Word": "Factor Analysis", "Description": "Factor analysis is a technique that is used to reduce a large number of variables into fewer numbers of factors. Factor analysis aims to find independent latent variables. Factor analysis also assumes several assumptions:\nThere is linear relationship\nThere is no multicollinearity\nIt includes relevant variables into analysis\nThere is true correlation between variables and factors\nThere are different types of methods used to extract the factor from the data set:\nPrincipal Component Analysis\nCommon factor analysis\nImage factoring\nMaximum likelihood method", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "233": {"Word": "False Negative", "Description": "Points which are actually true but are incorrectly predicted as false. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False negative in this case will be the samples for which loan was approved but the model predicted the status as not approved.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "234": {"Word": "False Positive", "Description": "Points which are actually false but are incorrectly predicted as true. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False positive in this case will be the samples for which loan was not approved but the model predicted the status as approved.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "235": {"Word": "Feature Hashing", "Description": "It is a method to transform features to vector. Without looking up the indices in an associative array, it applies a hash function to the features and uses their hash values as indices directly. Simple example of feature hashing:\nSuppose we have three documents:\nJohn likes to watch movies.\nMary likes movies too.\nJohn also likes football.\nNow we can convert this to vector using hashing.\nTerm Index\nJohn 1\nlikes 2\nto 3\nwatch 4\nmovies 5\nMary 6\ntoo 7\nalso 8\nfootball 9\nThe array form for the same will be:", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/hashing.png"]}, "236": {"Word": "Feature Reduction", "Description": "Feature reduction is the process of reducing the number of features to work on a computation intensive task without losing a lot of information.\nPCA is one of the most popular feature reduction techniques, where we combine correlated variables to reduce the features.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2016/03/1-1-1024x406.png"]}, "237": {"Word": "Feature Selection", "Description": "Feature Selection is a process of choosing those features which are required to explain the predictive power of a statistical model and dropping out irrelevant features.\nThis can be done by either filtering out less useful features or by combining features to make a new one.\nRefer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Filter_1.png"]}, "238": {"Word": "Few-shot Learning", "Description": "Few-shot learning refers to the training of machine learning algorithms using a very small set of training data instead of a very large set. This is most suitable in the field of computer vision, where it is desirable to have an object categorization model work well without thousands of training examples.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "239": {"Word": "Flume", "Description": "Flume is a service designed for streaming logs into the Hadoop environment. It can collect and aggregate huge amounts of log data from a variety of sources. In order to collect high volume of data, multiple flume agents can be configured.\nHere are the major features of Apache Flume:\nFlume is a flexible tool as it allows to scale in environments with as low as five machines to as high as several thousands of machines\nApache Flume provides high throughput and low latency\nApache Flume has a declarative configuration but provides ease of extensibility\nFlume in Hadoop is fault tolerant, linearly scalable and stream oriented", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "240": {"Word": "Frequentist Statistics", "Description": "Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment (i.e the experiment is repeated under the same conditions to obtain the outcome).\nHere, the sampling distributions of fixed size are taken. Then, the experiment is theoretically repeated infinite number of times but practically done with a stopping intention. For example, I perform an experiment with a stopping intention in mind that I will stop the experiment when it is repeated 1000 times or I see minimum 300 heads in a coin toss. Read more here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "241": {"Word": "F-Score", "Description": "F-score evaluation metric combines both precision and recall as a measure of effectiveness of classification. It is calculated in terms of ratio of weighted importance on either recall or precision as determined by \u03b2 coefficient.\nF measure = 2 x (Recall \u00d7 Precision) / ( \u03b2\u00b2 \u00d7 Recall + Precision )", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "242": {"Word": "Gated Recurrent Unit (GRU)", "Description": "The GRU is a variant of the LSTM (Long Short Term Memory) and was introduced by K. Cho. It retains the LSTM\u2019s resistance to the vanishing gradient problem, but because of its simpler internal structure it is faster to train.\nInstead of the input, forget, and output gates in the LSTM cell, the GRU cell has only two gates, an update gate z, and a reset gate r. The update gate defines how much previous memory to keep, and the reset gate defines how to combine the new input with the previous memory.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/GRU.png"]}, "243": {"Word": "Ggplot2", "Description": "GGplot2 is a data visualization package for the R programming language. It is a highly versatile and user-friendly tool for creating attractive plots. To know more about Ggplot2, visit here.\nIt can be easily installed using the following code from the R console:\ninstall.packages(\"ggplot2\")", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "244": {"Word": "Go", "Description": "Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. Go is a statically typed language in the tradition of C.\nThe main features of Go are:\nMemory safety\nGarbage collection\nStructural typing\nThe compiler and other tools originally developed by Google are all free and open source. To read further on the Go language, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "245": {"Word": "Goodness of Fit", "Description": "The goodness of fit of a model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model.\nWith regard to a machine learning algorithm, a good fit is when the error for the model on the training data as well as the test data is minimum. Over time, as the algorithm learns, the error for the model on the training data goes down and so does the error on the test dataset. If we train for too long, the performance on the training dataset may continue to decrease because the model is overfitting and learning the irrelevant detail and noise in the training dataset. At the same time the error for the test set starts to rise again as the model\u2019s ability to generalize decreases.\nSo the point just before the error on the test dataset starts to increase where the model has good skill on both the training dataset and the unseen test dataset is known as the good fit of the model.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "246": {"Word": "Gradient Descent", "Description": "Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. In machine learning algorithms, we use gradient descent to minimize the cost function. It find out the best set of parameters for our algorithm. Gradient Descent can be classified as follows:\nOn the basis of data ingestion:\nFull Batch Gradient Descent Algorithm\nStochastic Gradient Descent Algorithm\nIn full batch gradient descent algorithms, we use whole data at once to compute the gradient, whereas in stochastic we take a sample while computing the gradient.\nOn the basis of differentiation techniques:\nFirst order Differentiation\nSecond order Differentiation", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "247": {"Word": "Hadoop", "Description": "Hadoop is an open source distributed processing framework used when we have to deal with enormous data. It allows us to use parallel processing capability to handle big data. Here are some significant benefits of Hadoop:\nHadoop clusters work and keeps multiple copies to ensure reliability of data. A maximum of 4500 machines can be connected together using Hadoop\nThe whole process is broken down into pieces and executed in parallel, hence saving time. A maximum of 25 Petabyte (1 PB = 1000 TB) data can be processed using Hadoop\nIn case of a long query, Hadoop builds back up data-sets at every level. It also executes query on duplicate datasets to avoid process loss in case of individual failure. These steps makes Hadoop processing more precise and accurate\nQueries in Hadoop are as simple as coding in any language. You just need to change the way of thinking around building a query to enable parallel processing", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "248": {"Word": "Hidden Markov Model", "Description": "Hidden Markov Process is a Markov process in which the states are invisible or hidden, and the model developed to estimate these hidden states is known as the Hidden Markov Model (HMM). However, the output (data) dependent on the hidden states is visible. This output data generated by HMM gives some cue about the sequence of states.\nHMM are widely used for pattern recognition in speech recognition, part-of-speech tagging, handwriting recognition, and reinforcement learning.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "249": {"Word": "Hierarchical Clustering", "Description": "Hierarchical clustering, as the name suggests is an algorithm that builds hierarchy of clusters. This algorithm starts with all the data points assigned to a cluster of their own. Then two nearest clusters are merged into the same cluster. In the end, this algorithm terminates when there is only a single cluster left.\nThe results of hierarchical clustering can be shown using dendrogram. The dendrogram can be interpreted as:\n  Read more here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "250": {"Word": " Histogram", "Description": "Histogram is one of the methods for visualizing data distribution of continuous variables. For example, the figure below shows a histogram with age along the x-axis and frequency of the variable (count of passengers) along the y-axis.\nHistograms are widely used to determine the skewness of the data. Looking at the tail of the plot, you can find whether the data distribution is left skewed, normal or right skewed.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/h1.png", "https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/h2.png"]}, "251": {"Word": "Hive", "Description": "Hive is a data warehouse software project to process structured data in Hadoop. It is built on top of Apache Hadoop for providing data summarization, query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop. Some of the key features of Hive are :\nIndexing to provide acceleration\nDifferent storage types such as plain text, RDFile, HBase, ORC, and others\nMetadata storage in a relational database management system, significantly reducing the time to perform semantic checks during query execution\nOperating on compressed data stored into the Hadoop ecosystem\nFor detailed information, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "252": {"Word": "Holdout Sample", "Description": "While working on the dataset, a small part of the dataset is not used for training the model instead, it is used to check the performance of the model. This part of the dataset is called the holdout sample.\nFor instance, if I divide my data in two parts \u2013 7:3 and use the 70% to train the model, and other 30% to check the performance of my model, the 30% data is called the holdout sample.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "253": {"Word": "Holt-Winters Forecasting", "Description": "Holt-Winters is one of the most popular forecasting techniques for time series. The model predicts the future values computing the combined effects of both trend and seasonality. The idea behind Holt\u2019s Winter forecasting is to apply exponential smoothing to the seasonal components in addition to level and trend.\nVisit here for more details.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "254": {"Word": "Hyperparameter", "Description": "A hyperparameter is a parameter whose value is set before training a machine learning or deep learning model. Different models require different hyperparameters and some require none. Hyperparameters should not be confused with the parameters of the model because the parameters are estimated or learned from the data.\nSome keys points about the hyperparameters are:\nThey are often used in processes to help estimate model parameters.\nThey are often manually set.\nThey are often tuned to tweak a model\u2019s performance\nNumber of trees in a Random Forest, eta in XGBoost, and k in k-nearest neighbours are some examples of hyperparameters.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "255": {"Word": "Hyperplane", "Description": "It is a subspace with one fewer dimensions than its surrounding area. If a space is 3-dimensional then its hyperplane is just a normal 2D plane. In 5 dimensional space, it\u2019s a 4D plane, so on and so forth.\nMost of the time it\u2019s basically a normal plane, but in some special cases, like in Support Vector Machines, where classifications are performed with an n-dimensional hyperplane, the n can be quite large.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "256": {"Word": "Hypothesis", "Description": "Simply put, a hypothesis is a possible view or assertion of an analyst about the problem he or she is working upon. It may be true or may not be true.  Read more here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "257": {"Word": "Imputation", "Description": "Imputation is a technique used for handling missing values in the data. This is done either by statistical metrics like mean/mode imputation or by machine learning techniques like kNN imputation\n  For example,\nIf the data is as below\nName Age\nAkshay 23\nAkshat NA\nViraj 40\n  The second row contains a missing value, so to impute it we use mean of all ages, i.e.\nName Age\nAkshay 23\nAkshat 31.5\nViraj 40", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "258": {"Word": "Inferential Statistics", "Description": "In inferential statistics, we try to hypothesize about the population by only looking at a sample of it. For example, before releasing a drug in the market, internal tests are done to check if the drug is viable for release. But here we cannot check with the whole population for viability of the drug, so we do it on a sample which best represents the population.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "259": {"Word": "IQR", "Description": "IQR (or interquartile range) is a measure of variability based on dividing the rank-ordered data set into four equal parts. It can be derived by Quartile3 \u2013 Quartile1.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26081311/IQR.bmp"]}, "260": {"Word": "Iteration", "Description": "Iteration refers to the number of times an algorithm\u2019s parameters are updated while training a model on a dataset. For example, each iteration of training a neural network takes certain number of training data and updates the weights by using gradient descent or some other weight update rule.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "261": {"Word": "Julia", "Description": "Julia is a high-level, high-performance dynamic programming language for numerical computing. Some important features of Julia are:\nMultiple dispatch: providing the ability to define function behavior across many combinations of argument types.\nGood performance, approaching that of statically-compiled languages like C\nBuilt-in package manager\nDesigned for parallelism and distributed computation\nFree and open source", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "262": {"Word": "K-Means", "Description": "It is a type of unsupervised algorithm which solves the clustering problem. It is a procedure which follows a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters). Data points inside a cluster are homogeneous and heterogeneous to peer groups.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/08/splatter_ink_blot_texture_by_maki_tak-d5p6zph-284x300.jpg"]}, "263": {"Word": "Keras", "Description": "Keras is a simple, high-level neural network library, written in Python. It is capable of running on top of Tensorflow and Theano. This is done to make design and experiments with Neural Networks easier.\nFollowing are some important features of Keras:\nUser friendliness\nModularity\nEasy extensibility\nWork with Python", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "264": {"Word": "kNN", "Description": "K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its K nearest neighbors measured by a distance function.\nThese distance functions can be Euclidean, Manhattan, Minkowski and Hamming distance. First three functions are used for continuous function and fourth one (Hamming) for categorical variables. If K = 1, then the case is simply assigned to the class of its nearest neighbor. At times, choosing the value for K can be a challenge while performing KNN modeling.\n  Read more here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/08/KNN.png"]}, "265": {"Word": "Kurtosis", "Description": "Kurtosis is defined as the thickness (or heaviness) of the tails of a given distribution. Depending on the value of kurtosis, it can be classified into the below 3 categories:\nMesokurtic: The distribution with kurtosis value equal to 3. A random variable which follows a normal distribution has a kurtosis value of 3\nPlatykurtic: If the kurtosis is less than 3. In this, the given distribution has thinner tails and a lower peak than a normal distribution\nLeptykurtic: When the kurtosis value is greater than 3. In this, the given distribution has fatter tails and a higher peak than a normal distribution", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/kurtosis.gif"]}, "266": {"Word": "Labeled Data", "Description": "A labeled dataset has a meaningful \u201clabel\u201d, \u201cclass\u201d or \u201ctag\u201d associated with each of its records or rows. For example, labels for a dataset of a set of images might be whether an image contains a cat or a dog.\nLabeled data are usually more expensive to obtain than the raw unlabeled data because preparation of the labelled data involves manual labelling every piece of unlabeled data.\nLabeled data is required for supervised learning algorithms.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "267": {"Word": "Lasso Regression", "Description": "Lasso regression performs L1 regularization, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective. Thus, lasso regression optimizes the following:\nObjective = RSS + \u03b1 * (sum of absolute value of coefficients)\nHere, \u03b1 (alpha) works similar to that of ridge and provides a trade-off between balancing RSS and magnitude of coefficients. Like that of ridge, \u03b1 can take various values. Let\u2019s iterate it briefly here:\n\u03b1 = 0 : Same coefficients as simple linear regression\n\u03b1 = \u221e : All coefficients zero (same logic as before)\n0 < \u03b1 < \u221e : coefficients between 0 and that of simple linear regression", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "268": {"Word": "Line Chart", "Description": "Line charts are used to display information as series of points connected by straight line segment. These charts are used to communicate information visually, such as to show an increase or decrease in the trend in data over intervals of time.\nIn the plot below, for each time instance, the speed trend is shown and the points are connected to display the trend over time.\nThis plot is for a single case. Line charts can also be used to compare changes over the same period of time for multiple cases, like plotting the speed of a cycle, car, train over time in the same plot.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/line.png"]}, "269": {"Word": "Linear Regression", "Description": "The best way to understand linear regression is to relive this experience of childhood. Let us say, you ask a child in fifth grade to arrange people in his class by increasing order of weight, without asking them their weight! What do you think the child will do? He / she would likely look (visually analyze) at the height and build of people and arrange them using a combination of these visible parameters. This is linear regression in real life. The child has actually figured out that height and build would be correlated to the weight by a relationship, which looks like the equation below.\nY=aX+b\nwhere:\nY \u2013 Dependent Variable\na \u2013 Slope\nX \u2013 Independent variable\nb \u2013 Intercept\nThese coefficients a and b are derived based on minimizing the sum of squared difference of distance between data points and regression line.\nLook at the below example. Here we have identified the best fit line having linear equation y=0.2811x+13.9. Now using this equation, we can find the weight, knowing the height of a person.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/08/Linear_Regression.png"]}, "270": {"Word": "Log Loss", "Description": "Log Loss or Logistic loss is one of the evaluation metrics used to find how good the model is. Lower the log loss, better is the model. Log loss is the logarithm of the product of all probabilities.\nMathematically, log loss for two classes is defined as:\nwhere, y is the class label and p is the predicted probability.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/log-loss.png"]}, "271": {"Word": "Logistic Regression", "Description": "In simple words, it predicts the probability of occurrence of an event by fitting data to a logistic function. Hence, it is also known as logistic regression. Since, it predicts the probability, the  output values lies between 0 and 1 (as expected).", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "272": {"Word": "Long Short Term Memory (LSTM)", "Description": "Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for \u201cremembering\u201d values over arbitrary time intervals, hence the word \u201cmemory\u201d in LSTM. Each of the three gates can be thought of as a \u201cconventional\u201d artificial neuron, as in a multi-layer neural network, that is, they compute an activation (using an activation function) of a weighted sum. Applications of LSTM include:\nTime series predictions\nSpeech recognition\nRhythm learning\nHandwriting recognition\nTo learn further on LSTM, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "273": {"Word": " Machine Learning", "Description": "Machine Learning refers to the techniques involved in dealing with vast data in the most intelligent fashion (by developing algorithms) to derive actionable insights. In these techniques, we expect the algorithms to learn by itself wiithout being explicitly programmed.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "274": {"Word": "Mahout", "Description": "Mahout is an open source project from Apache that is used for creating scalable machine learning algorithms. It implements popular machine learning techniques such as recommendation, classification, clustering.\nFeatures of Mahout:\nMahout offers a framework for doing data mining tasks on large volumes of data\nMahout lets applications to analyze large sets of data effectively and in quick time\nIt also offers distributed fitness function capabilities for evolutionary programming\nIt includes several MapReduce enabled clustering implementations such as k-means, fuzzy k-means, Dirichlet, and Mean-Shift", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "275": {"Word": "MapReduce", "Description": "Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner.\nA MapReduce framework is usually composed of three operations:\nMap: each worker node applies the map function to the local data, and writes the output to a temporary storage. A master node ensures that only one copy of redundant input data is processed.\nShuffle: worker nodes redistribute data based on the output keys (produced by the map function), such that all data belonging to one key is located on the same worker node.\nReduce: worker nodes now process each group of output data, per key, in parallel.\nTo learn more about MapReduce, visit here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "276": {"Word": "Market Basket Analysis", "Description": "Market Basket Analysis (also called as MBA) is a widely used technique among the Marketers to identify the best possible combinatory of the products or services which are frequently bought by the customers. This is also called product association analysis.Association analysis mostly done based on an algorithm named \u201cApriori Algorithm\u201d. The Outcome of this analysis is called association rules. Marketers use these rules to strategize their recommendations.\nWhen two or more products are purchased, Market Basket Analysis is done to check whether the purchase of one product increases the likelihood of the purchase of other products. This knowledge is a tool for the marketers to bundle the products or strategize a product cross sell to a customer.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "277": {"Word": "Market Mix Modeling", "Description": "Market Mix Modeling is an analytical approach that uses historical information like point of sales to quantify the impact of some of the components on sales.\nSuppose the total sale is 100$, this total can be broken into sub components i.e. 60$ base sale, 20$ pricing, 18$ may be distribution and 2$ might be due to promotional activity. These numbers can be achieved using various logical methods. Every method can give a different break up. Hence, it becomes very important to standardize the process of breaking up the total sales into these components. This formal technique is formally known as MMM or Market Mix Modeling.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "278": {"Word": "Maximum Likelihood Estimation", "Description": "It is a method for finding the values of parameters which make the likelihood maximum. The resulting values are called maximum likelihood estimates (MLE).", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "279": {"Word": "Mean", "Description": "For a dataset, mean is said to be the average value of all the numbers. It can sometimes be used as a representation of the whole data.\nFor instance, if you have the marks of students from a class, and you asked about how good is the class performing. It would be irrelevant to say the marks of every single student, instead, you can find the mean of the class, which will be a representative for class performance.\nTo find the mean, sum all the numbers and then divide by the number of items in the set.\nFor example, if the numbers are 1,2,3,4,5,6,7,8,8 then the mean would be 44/9 = 4.89.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "280": {"Word": "Median", "Description": "Median of a set of numbers is usually the middle value. When the total numbers in the set are even, the median will be the average of the two middle values. Median is used to measure the central tendency.\nTo calculate the median for a set of numbers, follow the below steps:\nArrange the numbers in ascending or descending order\nFind the middle value, which will be n/2 (where n is the numbers in the set)", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "281": {"Word": "MIS", "Description": "A management information system (MIS) is a computer system consisting of hardware and software that serves as the backbone of an organization\u2019s operations. An MIS gathers data from multiple online systems, analyzes the information, and reports data to aid in management decision-making.\nObjectives of MIS:\nTo improve decision-making, by providing up-to-date, accurate data on a variety of organizational assets\nTo correlate multiple data points in order to strategize ways to improve operations", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "282": {"Word": "ML-as-a-Service (MLaaS)", "Description": "Machine learning as a service (MLaaS) is an array of services that provide machine learning tools as part of cloud computing services. This can include tools for data visualization, facial recognition, natural language processing, image recognition, predictive analytics, and deep learning. Some of the top ML-as-a-service providers are:\nMicrosoft Azure Machine Learning Studio\nAWS Machine Learning\nIBM Watson Machine Learning\nGoogle Cloud Machine Learning Engine\nBigML", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "283": {"Word": "Mode", "Description": "Mode is the most frequent value occuring in the population. It is a metric to measure the central tendency, i.e. a way of expressing, in a (usually) single number, important information about a random variable or a population.\nMode can be calculated using following steps:\nCount the number of time each value appears\nTake the value which appears the most\nLet us understand it with an example:\nSuppose we have a dataset having 10 data points, listed below:\n4,5,2,8,4,7,6,4,6,3\nSo now we will calculate the number of times each value has appeared.\nValue Count\n2 1\n3 1\n4 3\n5 1\n6 2\n7 1\n8 1\nSo we see that the value 4 is repeating the most, i.e., 3 times. So, the mode of this dataset will be 4.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "284": {"Word": "Model Selection", "Description": "Model selection is the task of selecting a statistical model from a set of known models. Various methods that can be used for choosing the model are:\nExploratory Data Analysis\nScientific Methods\nSome of the criteria for selecting the model can be:\nAkaike Information Criterion (AIC)\nAdjusted R2\nBayesian Information Criterion (BIC)\nLikelihood ratio test", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "285": {"Word": "Monte Carlo Simluation", "Description": "The idea behind Monte Carlo Simulation is to use random samples of parameters or inputs to explore the behavior of a complex process. Monte Carlo simulations sample from a probability distribution for each variable to produce hundreds or thousands of possible outcomes. The results are analyzed to get probabilities of different outcomes occurring.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "286": {"Word": "Multi-Class Classification", "Description": "Problems which have more than one class in the target variable are called multi-class Classification problems.\nFor example, if the target is to predict the quality of a product, which can be Excellent, good, average, fair, bad. In this case, the variable has 5 classes, hence it is a 5-class classification problem.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "287": {"Word": "Multivariate Analysis", "Description": "Multivariate analysis is a process of comparing and analyzing the dependency of multiple variables over each other.\nFor example, we can perform bivariate analysis of combination of two continuous features and find a relationship between them.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Data_exploration_4.png"]}, "288": {"Word": "Multivariate Regression", "Description": "Multivariate, as the word suggests, refers to \u2018multiple dependent variables\u2019. A regression model designed to deal with multiple dependent variables is called a multivariate regression model.\nConsider the example \u2013 for a given set of details about a student\u2019s interests, previous subject-wise score etc, you want to predict the GPA for all the semesters (GPA1, GPA2, \u2026. ). This problem statement can be addressed using multivariate regression since we have more than one dependent variable.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "289": {"Word": "Naive Bayes", "Description": "It is a classification technique based on Bayes\u2019 theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. For example, a fruit may be considered to be an apple if it is red, round and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, a naive Bayes classifier would consider all of these properties to independently contribute to the probability that this fruit is an apple.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "290": {"Word": "NaN", "Description": "NaN stands for \u2018not a number\u2019. It is a numeric data type value representing an undefined or unrepresentable value. If the dataset has NaN values somewhere, it means that the data at that location is either missing or represented incorrectly.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "291": {"Word": "Natural Language Processing", "Description": "In simple words, Natural Language Processing is a field which aims to make computer systems understand human speech. NLP is comprised of techniques to process, structure, categorize raw text and extract information.\nChatBot is a classic example of NLP, where sentences are first processed, cleaned and converted to machine understandable format.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "292": {"Word": "NoSQL", "Description": "NoSQL means Not only SQL. A NoSQL database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. It can accommodate a wide variety of data models, including key-value, document, columnar and graph formats.\nTypes of NoSQL:\nColumn\nDocument\nKey-Value\nGraph\nMulti-model\nTo learn more about NoSQL and its types, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "293": {"Word": "Nominal Variable", "Description": "Nominal variables are categorical variables having two or more categories without any kind of order to them.\nFor example, a column called \u201cname of cities\u201d with values such as Delhi, Mumbai, Chennai, etc.\nWe can see that there is no order between the variables \u2013 viz Delhi is in no particular way higher or lower than Mumbai (unless explicitly mentioned).", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "294": {"Word": "Normal Distribution", "Description": "The normal distribution is the most important and most widely used distribution in statistics. It is sometimes called the bell curve, because it has a peculiar shape of a bell. Mostly, a binomial distribution is similar to normal distribution. The difference between the two is normal distribution is continuous.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/09/SND.png"]}, "295": {"Word": "Normalization", "Description": "Normalization is the process of rescaling your data so that they have the same scale. Normalization is used when the attributes in our data have varying scales.\nFor example, if you have a variable ranging from 0 to 1 and other from 0 to 1000, you can normalize the variable, such that both are in the range 0 to 1.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "296": {"Word": "Numpy", "Description": "NumPy is the fundamental package for scientific computing with Python. It contains among other things:\na powerful N-dimensional array object\nsophisticated (broadcasting) functions\ntools for integrating C/C++ and Fortran code\nuseful linear algebra, Fourier transform, and random number capabilities\nBesides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "297": {"Word": "One Hot Encoding", "Description": "One Hot encoding is done usually in the preprocessing step. It is a technique which converts categorical variables to numerical in an interpretable format. In this we create a Boolean column for each category of the variable.\nFor example, if the data is\nSr. No. Name\n1 Vivek\n2 Akshat\n3 Arshad\nThis is converted as\nSr. No. Vivek Akshat Arshad\n1 1 0 0\n2 0 1 0\n3 0 0 1", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "298": {"Word": "One Shot Learning", "Description": "It is a machine learning approach where the model is trained on a single example. One-shot Learning is generally used for object classification. This is performed to design effective classifiers from a single training example.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "299": {"Word": "Oozie", "Description": "Apache Oozie is the tool in which all sort of programs can be pipelined in a desired order to work in Hadoop\u2019s distributed environment. Oozie also provides a mechanism to run the job at a given schedule.\nIt consists of two parts:\nWorkflow engine: Responsibility of a workflow engine is to store and run workflows composed of Hadoop jobs e.g., MapReduce, Pig, Hive.\nCoordinator engine: It runs workflow jobs based on predefined schedules and availability of data.\nFeatures of Oozie:\nOozie has client API and command line interface which can be used to launch, control and monitor job from Java application.\nUsing its Web Service APIs one can control jobs from anywhere.\nOozie has provision to execute jobs which are scheduled to run periodically.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "300": {"Word": "Ordinal Variable", "Description": "Ordinal variables are those variables which have discrete values but has some order involved. Refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "301": {"Word": "Outlier", "Description": "Outlier is an observation that appears far away and diverges from an overall pattern in a sample.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26114329/outlier_scatterplot.png"]}, "302": {"Word": "Overfitting", "Description": "A model is said to overfit when it performs well on the train dataset but fails on the test set. This happens when the model is too sensitive and captures random patterns which are present only in the training dataset. There are two methods to overcome overfitting:\nReduce the model complexity\nRegularization", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "303": {"Word": "Pandas", "Description": "Pandas is an open source, high-performance, easy-to-use data structure and data analysis library for the Python programming language. Some of the highlights of Pandas are:\nA fast and efficient DataFrame object for data manipulation with integrated indexing.\nTools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format.\nFlexible reshaping and pivoting of data sets.\nColumns can be inserted and deleted from data structures for size mutability.\nHigh performance merging and joining of data sets.\nFor more information on Pandas, you can refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "304": {"Word": "Parameters", "Description": "Parameters are a set of measurable factors that define a system. For machine learning models, model parameters are internal variables whose values can be determined from the data.\nFor instance, the weights in linear and logistic regression fall under the category of parameters.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "305": {"Word": "Pattern Recognition", "Description": "Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data. Classification is an example of pattern recognition wherein each input value is assigned one of a given set of classes.  \nIn computer vision, supervised pattern recognition techniques are used for optical character recognition (OCR), face detection, face recognition, object detection, and object classification.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/PR.png"]}, "306": {"Word": "Pie Chart", "Description": "A pie chart is a circular statistical graphic which is divided into slices to illustrate numerical proportion. The arc length of each slice, is proportional to the quantity it represents. Let us understand it with an example:\nThis represents a pie graph showing the results of an exam. Each grade is denoted by a \u201cslice\u201d. The total of the percentages is equal to 100. The total of the arc measures is equal to 360 degrees. So 12% students got A grade, 29% got B, and so on.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/pie.png"]}, "307": {"Word": "Pig", "Description": "Pig is a high level scripting language that is used with Apache Hadoop. Pig enables data workers to write complex data transformations without knowing Java. Pig is complete, so one can do all required data manipulations in Apache Hadoop with Pig. Through the User Defined Functions(UDF) facility in Pig, Pig can invoke code in many languages like JRuby, Jython and Java.\nKey features of Pig:\nIt is able to store data at any point during a pipeline.\nIt declares execution plans.\nSupports pipeline splits, thus allowing workflows to proceed along DAGs instead of strictly sequential pipelines.\nUsers can create their own functions to do special-purpose processing.\nTo read further on Pig, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "308": {"Word": "Polynomial Regression", "Description": "In this technique, a curve fits into the data points. In a polynomial regression equation, the power of the independent variable is greater than 1. Although higher degree polynomials give lower error, they might also result in over-fitting.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/Poly.png", "https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/PR.png"]}, "309": {"Word": "Pre-trained Model", "Description": "A pre-trained model is a model created by someone else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, you use the model trained on other problem as a starting point.\nFor example, if you want to build a self learning car. You can spend years to build a decent image recognition algorithm from scratch or you can take inception model (a pre-trained model) from Google which was built on ImageNet data to identify images in those pictures.\nFor more information regarding Pre-trained model and their usages, you can refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/PR.png"]}, "310": {"Word": "Precision and Recall", "Description": "Precision can be measured as of the total actual positive cases, how many positives were predicted correctly.\nIt can be represented as:\nPrecision = TP / (TP + FP)\nWhereas recall is described as the measured of how many of the positive predictions were correct.\nIt can be represented as:\nRecall = TP / (TP + FN)", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/PR.png"]}, "311": {"Word": "Predictor Variable", "Description": "Predictor variable is used to make a prediction for dependent variables.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "312": {"Word": "Principal Component Analysis (PCA)", "Description": "Principal component analysis (PCA) is an approach to factor analysis that considers the total variance in the data, and transforms the original variables into a smaller set of linear combinations. PCA is sensitive to outliers; they should be removed.\nIt is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.\nPCA is mostly used as a tool in exploratory data analysis and for making predictive models. It\u2019s often used to visualize genetic distance and relatedness between populations.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "313": {"Word": "P-Value", "Description": "P-value is the value of probability of getting a result equal to or greater than the observed value, when the null hypothesis is true.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "314": {"Word": "Python", "Description": "Python is an open source programming language, widely used for various applications, such as general purpose programming, data science and machine learning. Usually preferred by beginners in these fields because of the following major advantages:\nEasy to learn.\nHigh-level language\nBroadly used and supported\nTo learn python from scratch, you can follow this article.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "315": {"Word": "PyTorch", "Description": "PyTorch is an open source machine learning library for python, based on Torch. It is built to provide flexibility as a deep learning development platform. Here are a few reasons for which PyTorch is extensively used :\nEasy to use API\nPython support\nDynamic computation graphs", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "316": {"Word": "Quartile", "Description": "Quartile divides a series into 4 equal parts. For any series, there are 4 quartiles denoted by Q1, Q2, Q3 and Q4. These are known as First Quartile , Second Quartile and so on.\nFor example, the diagram below shows the health score of a patient from range 0 to 60. Quartiles divide the population into 4 groups.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26081018/histoQuantiles.gif"]}, "317": {"Word": " R", "Description": "R is an open-source programming language and a software environment for statistical computing, machine learning, and data visualization.\nFeatures of R:\nIt is platform independent, so it is compatible with multiple operating systems\nR has a very strong and consistent online community support\nThe graphical capabilities of R are awesome\nThere is abundance of literature to learn R", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "318": {"Word": " Range", "Description": "Range is the difference between the highest and the lowest value of the population. It is used to measure the spread of the data.Let us understand it with an example:\nSuppose we have a dataset having 10 data points, listed below:\n4,5,2,8,4,7,6,4,6,3\nSo, first of all we will arrange these data points in ascending order:\n2,3,4,4,4,5,6,6,7,8\nNow the range of this set is the difference between the highest(8) and the lowest(2) value.\nRange = 8-2 = 6", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "319": {"Word": "Recommendation Engine", "Description": "Generally people tend to buy products recommended to them by their friends or the people they trust. Nowadays in the digital age, any online shop you visit utilizes some sort of recommendation engine. Recommendation engines basically are data filtering tools that make use of algorithms and data to recommend the most relevant items to a particular user. If we can recommend items to a customer based on their needs and interests, it will create a positive effect on the user experience and they will visit more frequently. There are few types of recommendation engines:\nContent based filtering\nCollaborative filtering\nUser-User collaborative filtering\nItem-Item collaborative filtering\nHybrid recommendation systems", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "320": {"Word": "Regression", "Description": "It is supervised learning method where the output variable is a real value, such as \u201camount\u201d or \u201cweight\u201d.\nExample of Regression: Linear Regression, Ridge Regression, Lasso Regression", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "321": {"Word": "Regression Spline", "Description": "Regression Splines is a non-linear approach that uses a combination of linear/polynomial functions to fit the data. In this technique, instead of building one model for the entire dataset, it is divided into multiple bins and a separate model is built on each bin.\nRead more about this topic here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "322": {"Word": "Regularization", "Description": "Regularization is a technique used to solve the overfitting problem in statistical models. In machine learning, regularization penalizes the coefficients such that the model generalize better. We have different types of regression techniques which uses regularization such as Ridge regression and lasso regression.\n ", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "323": {"Word": " Reinforcement Learning", "Description": " It is an example of machine learning where the machine is trained to take specific decisions based on the business requirement with the sole motto to maximize efficiency (performance). The idea involved in reinforcement learning is: The machine/ software agent trains itself on a continual basis based on the environment it is exposed to, and applies it\u2019s enriched knowledge to solve business problems. This continual learning process ensures less involvement of human expertise which in turn saves a lot of time!\nImportant Note: There is a subtle difference between Supervised Learning and Reinforcement Learning (RL). RL essentially involves learning by interacting with an environment. An RL agent learns from its past experience, rather from its continual trial and error learning process as against supervised learning where an external supervisor  provides examples.\nA good example to understand the difference is self driving cars. Self driving cars use Reinforcement learning to make decisions continuously like which route to take, what speed to drive on, are some of the questions which are decided after interacting with the environment. A simple manifestation for supervised learning would be to predict the total fare of a cab at the end of a journey.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "324": {"Word": "Residual", "Description": "Residual of a value is the difference between the observed value and the predicted value of the quantity of interest. Using the residual values, you can create residual plots which are useful for understanding the model.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "325": {"Word": "Response Variable", "Description": "Response variable (or dependent variable) is that variable whose variation depends on other variables.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "326": {"Word": "Ridge Regression", "Description": "Ridge regression performs \u2018L2 regularization\u2018, i.e. it adds a factor of sum of squares of coefficients in the optimization objective. Thus, ridge regression optimizes the following:\nObjective = RSS + \u03b1 * (sum of square of coefficients)\nHere, \u03b1 (alpha) is the parameter which balances the amount of emphasis given to minimizing RSS vs minimizing sum of squares of coefficients. \u03b1 can take various values:\n\u03b1 = 0:\nThe objective becomes same as simple linear regression.\nWe\u2019ll get the same coefficients as simple linear regression.\n\u03b1 = \u221e:\nThe coefficients will be zero. This is because of infinite weightage on square of coefficients, anything less than zero will make the objective infinite.\n0 < \u03b1 < \u221e:\nThe magnitude of \u03b1 will decide the weightage given to different parts of objective.\nThe coefficients will be somewhere between 0 and 1 for simple linear regression.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "327": {"Word": "ROC-AUC", "Description": "Let\u2019s first understand what is ROC (Receiver operating characteristic) curve. If we look at the confusion matrix, we observe that for a probabilistic model, we get different value for each metric.\nHence, for each sensitivity, we get a different specificity. The two vary as follows:\nThe ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate. Following is the ROC curve for the case in hand.\nLet\u2019s take an example of threshold = 0.5 (refer to confusion matrix). Here is the confusion matrix :\nAs you can see, the sensitivity at this threshold is 99.6% and the (1-specificity) is ~60%. This coordinate becomes on point in our ROC curve. To bring this curve down to a single number, we find the area under this curve (AUC).\nNote that the area of entire square is 1*1 = 1. Hence, AUC itself is the ratio under the curve and the total area.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/Confusion_matrix.png", "https://www.analyticsvidhya.com/wp-content/uploads/2015/01/curves.png", "https://www.analyticsvidhya.com/wp-content/uploads/2015/01/ROC.png"]}, "328": {"Word": "Root Mean Squared Error (RMSE)", "Description": "RMSE is a measure of the differences between values predicted by a model or an estimator and the values actually observed. It is the standard deviation of the residuals. Residuals are a measure of how far from the regression line data points are. The formula for RMSE is given by:\nHere,\nPredicted -> value predicted by the model\nActual -> observed values\nN -> Total number of observations", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/rmse.png"]}, "329": {"Word": "Rotational Invariance", "Description": "In mathematics, a function defined on an inner product space is said to have rotational invariance if its value does not change when arbitrary rotations are applied to its argument. For example, the function:\nis invariant under rotations of the plane around the origin, because for a rotated set of coordinates through any angle \u03b8.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/06/RI.png"]}, "330": {"Word": "Scala", "Description": "Scala is a general purpose language that combines concepts of object-oriented and functional programming languages. Here are some key features of Scala\nIts an object-oriented language that supports many traditional design patterns\nIt supports functional programming which enables it to handle distributed programming at fundamental level\nIt is designed to run on JVM platform that helps in directly using Java libraries\nScala can be easily implemented into existing java projects as Scala libraries can be used within Java code\nIt supports first-class objects and anonymous functions", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "331": {"Word": " Semi-Supervised Learning", "Description": "Problems where you have a large amount of input data (X) and only some of the data, is labeled (Y) are called semi-supervised learning problems.\nThese problems sit in between both supervised and unsupervised learning.\nA good example is a photo archive where only some of the images are labeled, (e.g. dog, cat, person) and the majority are unlabeled.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "332": {"Word": "Skewness", "Description": "Skewness is a measure of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26082133/skewkurt.jpg"]}, "333": {"Word": "SMOTE", "Description": "It is a Synthetic Minority Over-Sampling Technique which is an approach to the construction of classifiers from imbalanced datasets is described. The idea behind this technique is that over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This is an over-sampling approach in which the minority class is over-sampled by creating \u201csynthetic\u201d examples rather than by over-sampling with replacement. To read further on SMOTE, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "334": {"Word": "Spatial-Temporal Reasoning", "Description": "Spatial-temporal reasoning is an area of artificial intelligence which draws from the fields of computer science, cognitive science, and cognitive psychology. Spatial-temporal reasoning is the ability to mentally move objects in space and time to solve multi-step problems. Three important things about Spatial-temporal reasoning are:\nIt connects to mathematics at all levels, from kindergarten to calculus\nIt is innate in humans\nSpatial-temporal reasoning abilities can be increased. This understanding of Spatial-temporal reasoning forms the foundation of Spatial-temporal Math", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "335": {"Word": "Standard Deviation", "Description": "Standard deviation signifies how dispersed is the data. It is the square root of the variance of underlying data. Standard deviation is calculated for a population.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "336": {"Word": "Standardization", "Description": "Standardization (or Z-score normalization) is the process where the features are rescaled so that they\u2019ll have the properties of a standard normal distribution with \u03bc=0 and \u03c3=1, where \u03bc is the mean (average) and \u03c3 is the standard deviation from the mean. Standard scores (also called z scores) of the samples are calculated as follows:", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/standardization.png"]}, "337": {"Word": "Standard error", "Description": "A standard error is the standard deviation of the sampling distribution of a statistic. The standard error is a statistical term that measures the accuracy of which a sample represents a population. In statistics, a sample mean deviates from the actual mean of a population this deviation is known as standard error.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "338": {"Word": "Statistics", "Description": "It is the study of the collection, analysis, interpretation, presentation, and organisation of data.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "339": {"Word": "Stochastic Gradient Descent", "Description": "Stochastic Gradient Descent is a type of gradient descent algorithm where we take a sample of data while computing the gradient. The update to the coefficients is performed for each training instance, rather than at the end of the batch of instances.\nThe learning can be much faster with stochastic gradient descent for very large training datasets and often one only need a small number of passes through the dataset to reach a good or good enough set of coefficients.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "340": {"Word": " Supervised Learning", "Description": "Supervised Learning algorithm consists of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of predictors, we generate a function that map inputs to desired outputs. Like: y= f(x)\nHere, The goal is to approximate the mapping function so well that when you have new input data (x) that you can predict the output variables (Y) for that data.\nExamples of Supervised Learning algorithms: Regression, Decision Tree, Random Forest, KNN, Logistic Regression etc.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "341": {"Word": "SVM", "Description": "It is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is the number of features you have) with the value of each feature being the value of a particular coordinate.\nFor example, if we only have two features like Height and Hair length of an individual, we\u2019d first plot these two variables in two-dimensional space where each point has two coordinates (these coordinates are known as Support Vectors) Now, we will find some line that splits the data between the two differently classified groups of data. This will be the line such that the distances from the closest point in each of the two groups will be farthest away.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://www.analyticsvidhya.com/wp-content/uploads/2015/08/SVM2.png"]}, "342": {"Word": "TensorFlow", "Description": "TensorFlow, developed by the Google Brain team, is an open source software library. It is used for building machine learning models for range of tasks in data science, mainly used for machine learning applications such as building neural networks. TensorFlow can also be used for non- machine learning tasks that require numerical computation.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "343": {"Word": "Tokenization", "Description": "Tokenization is the process of splitting a text string into units called tokens. The tokens may be words or a group of words. It is a crucial step in Natural Language Processing.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "344": {"Word": "Torch", "Description": "Torch is an open source machine learning library, based on the Lua programming language. It provides a wide range of algorithms for deep learning.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "345": {"Word": "Transfer Learning", "Description": "Transfer learning refers to applying a pre-trained model on a new dataset. A pre-trained model is a model created by someone to solve a problem. This model can be applied to solve a similar problem with similar data.\nHere you can check some of the most widely used pre-trained models.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "346": {"Word": "True Negative", "Description": "These are the points which are actually false and we have predicted them false. For example, consider an example where we have to predict whether the loan will be approved or not. Y represents that loan will be approved, whereas N represents that loan will not be approved. So, here the True negative will be the number of classes which are actually N and we have predicted them N as well.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "347": {"Word": "True Positive", "Description": "These are the points which are actually true and we have predicted them true. For example, consider an example where we have to predict whether the loan will be approved or not. Y represents that loan will be approved, whereas N represents that loan will not be approved. So, here the True positive will be the number of classes which are actually Y and we have predicted them Y as well.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "348": {"Word": "Type I error", "Description": "The decision to reject the null hypothesis could be incorrect, it is known as Type I error.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26114653/hl_nullhypo_errors-300x178.png"]}, "349": {"Word": "Type II error", "Description": "The decision to retain the null hypothesis could be incorrect, it is know as Type II error.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/12/26114653/hl_nullhypo_errors-300x178.png"]}, "350": {"Word": "T-Test", "Description": "T-test is used to compare two population by finding the difference of their population means. For more, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "351": {"Word": "Underfitting", "Description": "Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It refers to a model that can neither model on the training data nor generalize to new data. An underfit model is not a suitable model as it will have poor performance on the training data.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "352": {"Word": "Univariate Analysis", "Description": "Univariate analysis is comparing and analyzing the dependency of a single predictor and a response variable", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "353": {"Word": " Unsupervised Learning", "Description": "In Unsupervised Learning algorithm, we do not have any target or outcome variable to predict/estimate. The goal of unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data or segment into different groups based on their attributes.Examples of Unsupervised Learning algorithm: Apriori algorithm, K-means.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "354": {"Word": "Variance", "Description": "Variance is used to measure the spread of given set of numbers and calculated by the average of squared distances from the mean\nLet\u2019s take an example, suppose the set of numbers we have is (600, 470, 170, 430, 300)\nTo Calculate:\n1) Find the Mean of set of numbers, which is (600 + 470 + 170 + 430 + 300) / 5 = 394\n2) Subtract the mean from each value which is (206, 76, -334, 36, -94)\n3) Square each deviation from the mean which is (42436, 5776, 50176, 1296, 8836)\n4) Find the Sum of Squares which is 108520\n5) Divide by total number of items (numbers) which is 21704", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}, "355": {"Word": "Z-test", "Description": "Z-test determines to what extent a data point is away from the mean of the data set, in standard deviation. For example:\nPrincipal at a certain school claims that the students in his school are above average intelligence. A random sample of thirty students has a mean IQ score of 112. The mean population IQ is 100 with a standard deviation of 15. Is there sufficient evidence to support the principal\u2019s claim?\nSo we can make use of z-test to test the claims made by the principal. Steps to perform z-test:\nStating null hypothesis and alternate hypothesis.\nState the alpha level. If you don\u2019t have an alpha level, use 5% (0.05).\nFind the rejection region area (given by your alpha level above) from the z-table. An area of .05 is equal to a z-score of 1.645.\nFind the test statistics using this formula:\nHere,\nx \u0305is the sample mean\n\u03c3 is population standard deviation\nn is sample size\n\u03bc is the population mean\nIf the test statistic is greater than the z-score of rejection area, reject the null hypothesis. If it\u2019s less than that z-score, you cannot reject the null hypothesis.\nTo get a better understanding of the topic, refer here.", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": ["https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/z-test.png"]}, "356": {"Word": "Zookeeper", "Description": "ZooKeeper is a software project of the Apache Software Foundation. It is an open source file application program interface (API) that allows distributed processes in large systems to synchronize with each other so that all clients making requests receive consistent data.\n ", "Url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/", "Attachment_Url": []}}